[{"id": "70b6b1f8-0b6d-46a5-b307-1fd4d66ad2ca", "input": "Spurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation refers to a situation where data appears to be related but is not actually connected.\",\n            \"explanation\": \"In the context of the provided text, it illustrates this concept with the example of a cow that is always seen against a green background. The AI mistakenly assumes that the cow is not a cow if it appears in a different background.\"\n        },\n        {\n            \"question\": \"What example is given to illustrate spurious correlation?\",\n            \"answer\": \"The example given is a cow that is always in a green background.\",\n            \"explanation\": \"The text explains that because the AI has only seen the cow in a green background, it may incorrectly conclude that an object not in that background is not a cow, demonstrating how spurious correlations can lead to incorrect assumptions.\"\n        }\n    ]\n}"}, {"id": "5a964cc4-356a-49eb-b672-edce12a066cc", "input": "#history-section {\r\n    width: 100%; /* Ensure full width for centering */\r\n    display: flex;\r\n    flex-direction: column;\r\n    align-items: center; /* Center the flashcards */\r\n}\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What does the 'width' property in the CSS rule for #history-section do?\",\n            \"answer\": \"It sets the width of the #history-section to 100%.\",\n            \"explanation\": \"This ensures that the section takes up the full width of its parent container, which is important for centering the content.\"\n        },\n        {\n            \"question\": \"What is the purpose of 'display: flex;' in the #history-section CSS?\",\n            \"answer\": \"It enables the flexbox layout model for the #history-section.\",\n            \"explanation\": \"Using flexbox allows for more efficient arrangement of child elements, making it easier to align and distribute space among them.\"\n        },\n        {\n            \"question\": \"How does 'flex-direction: column;' affect the layout of #history-section?\",\n            \"answer\": \"It arranges the child elements in a vertical column.\",\n            \"explanation\": \"This means that the items within #history-section will stack on top of each other rather than being laid out in a row.\"\n        },\n        {\n            \"question\": \"What does 'align-items: center;' achieve in the #history-section?\",\n            \"answer\": \"It centers the child elements horizontally within the #history-section.\",\n            \"explanation\": \"This alignment ensures that all child elements are positioned in the center of the flex container, enhancing visual symmetry.\"\n        }\n    ]\n}"}, {"id": "e428dec9-c9f0-4f13-9729-1747079448d0", "input": "#history-section {\r\n    width: 100%; /* Ensure full width for centering */\r\n    display: flex;\r\n    flex-direction: column;\r\n    align-items: center; /* Center the flashcards */\r\n}\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What CSS property is used to set the width of the #history-section?\",\n            \"answer\": \"width: 100%;\",\n            \"explanation\": \"This property ensures that the #history-section takes the full width of its parent container.\"\n        },\n        {\n            \"question\": \"What display type is applied to the #history-section?\",\n            \"answer\": \"display: flex;\",\n            \"explanation\": \"The flex display type allows for a flexible layout, enabling the child elements to be arranged in a flexible manner.\"\n        },\n        {\n            \"question\": \"What is the purpose of 'flex-direction: column;' in the #history-section?\",\n            \"answer\": \"It arranges the child elements in a vertical column.\",\n            \"explanation\": \"Setting the flex-direction to column makes the flex items stack vertically instead of horizontally.\"\n        },\n        {\n            \"question\": \"What does 'align-items: center;' achieve in the #history-section?\",\n            \"answer\": \"It centers the flashcards within the section.\",\n            \"explanation\": \"This property aligns the flex items along the cross axis, which in this case is horizontal, centering them within the container.\"\n        }\n    ]\n}"}, {"id": "32a15593-3549-4c68-86f6-b6d0b9990b35", "input": "#history-section {\r\n    width: 100%; /* Ensure full width for centering */\r\n    display: flex;\r\n    flex-direction: column;\r\n    align-items: center; /* Center the flashcards */\r\n}\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What CSS property is used to ensure the section takes the full width of its container?\",\n            \"answer\": \"width: 100%;\",\n            \"explanation\": \"The 'width: 100%;' property sets the width of the #history-section to occupy the entire width of its parent container.\"\n        },\n        {\n            \"question\": \"What CSS display property is used for the #history-section?\",\n            \"answer\": \"display: flex;\",\n            \"explanation\": \"The 'display: flex;' property enables a flexbox layout for the #history-section, allowing for responsive alignment of its child elements.\"\n        },\n        {\n            \"question\": \"How are the child elements of #history-section aligned?\",\n            \"answer\": \"align-items: center;\",\n            \"explanation\": \"The 'align-items: center;' property centers the child elements vertically within the flex container.\"\n        },\n        {\n            \"question\": \"What is the flex-direction set to in the #history-section?\",\n            \"answer\": \"flex-direction: column;\",\n            \"explanation\": \"The 'flex-direction: column;' property arranges the child elements in a vertical stack.\"\n        }\n    ]\n}"}, {"id": "cdbee76a-eba6-49a6-92f2-ae4881ba2507", "input": "Spurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation refers to a situation when data appears to be related but is not.\",\n            \"explanation\": \"This means that two variables may seem to have a relationship due to coincidental factors or confounding variables, rather than a direct causal relationship.\"\n        },\n        {\n            \"question\": \"Can you give an example of spurious correlation?\",\n            \"answer\": \"An example is a cow always being in a green background, leading AI to assume that if a cow is in a different background, it is not a cow.\",\n            \"explanation\": \"This illustrates how the AI's assumption is based on the background color rather than the actual characteristics of the cow, demonstrating a false correlation.\"\n        }\n    ]\n}"}, {"id": "e5feab8f-e75e-43d3-9643-1700cf6e6008", "input": "document.getElementById('toggle-taskbar').addEventListener('click', function () {\r\n    const taskbar = document.getElementById('taskbar');\r\n    const mainContent = document.getElementById('main-content');\r\n    taskbar.classList.toggle('minimized');\r\n    mainContent.classList.toggle('expanded');\r\n});\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What event is being listened for in the provided code?\",\n            \"answer\": \"A click event on the element with the ID 'toggle-taskbar'.\",\n            \"explanation\": \"The code uses 'addEventListener' to listen for a click on the button or element with the ID 'toggle-taskbar', triggering the function when the event occurs.\"\n        },\n        {\n            \"question\": \"What happens to the 'taskbar' and 'mainContent' elements when the event occurs?\",\n            \"answer\": \"The 'taskbar' element gets toggled between minimized and expanded states, and the 'mainContent' element gets toggled between expanded and minimized states.\",\n            \"explanation\": \"The 'classList.toggle' method is called on both elements, which adds or removes the specified classes ('minimized' for the taskbar and 'expanded' for the main content), effectively changing their display states.\"\n        }\n    ]\n}"}, {"id": "a0c6d59b-eca9-4250-942d-40202ecd4cf2", "input": ".taskbar.minimized a[href='/history']:before {\r\n            content: \"\";\r\n            /* Ensure no emoji or extra content is shown */\r\n        }\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What does the CSS rule '.taskbar.minimized a[href='/history']:before' target?\",\n            \"answer\": \"It targets the 'before' pseudo-element of anchor tags within a minimized taskbar that link to '/history'.\",\n            \"explanation\": \"The selector '.taskbar.minimized a[href='/history']:before' specifies styles that will apply to the 'before' pseudo-element of anchor elements that match the criteria, which are contained within a parent element with the classes 'taskbar' and 'minimized'.\"\n        },\n        {\n            \"question\": \"What is the purpose of the 'content' property in this CSS rule?\",\n            \"answer\": \"The 'content' property is set to an empty string.\",\n            \"explanation\": \"Setting the 'content' property to an empty string ensures that no emoji or any other extra content is displayed before the anchor element, effectively hiding any default content that might appear.\"\n        }\n    ]\n}"}, {"id": "d80ea917-f759-43f3-80e7-f5d8b1fbf60e", "input": ".taskbar.minimized a[href='/history']:before {\r\n            content: \"\";\r\n            /* Ensure no emoji or extra content is shown */\r\n        }\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What does the CSS rule '.taskbar.minimized a[href='/history']:before' target?\",\n            \"answer\": \"It targets the 'before' pseudo-element of anchor tags within a minimized taskbar that link to '/history'.\",\n            \"explanation\": \"The selector '.taskbar.minimized a[href='/history']' specifically selects anchor elements that are direct children of an element with the class 'taskbar' and 'minimized', and that have an href attribute equal to '/history'. The ':before' pseudo-element is used to insert content before the selected element.\"\n        },\n        {\n            \"question\": \"What is the purpose of the 'content' property set to an empty string?\",\n            \"answer\": \"It ensures that no emoji or extra content is displayed before the link.\",\n            \"explanation\": \"By setting the 'content' property to an empty string, the CSS rule effectively removes any default content that might be added by the browser, such as icons or emojis, ensuring that only the link text is visible.\"\n        }\n    ]\n}"}, {"id": "e910617c-0f50-44dd-909a-a86380cbcc56", "input": ".taskbar.minimized a[href='/history']:before {\r\n            content: \"\";\r\n            /* Ensure no emoji or extra content is shown */\r\n        }\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What does the CSS rule '.taskbar.minimized a[href='/history']:before' target?\",\n            \"answer\": \"It targets the 'before' pseudo-element of anchor tags within a minimized taskbar that link to the '/history' page.\",\n            \"explanation\": \"The selector specifies that it applies to anchor ('a') elements that have an 'href' attribute equal to '/history' and are descendants of an element with the classes 'taskbar' and 'minimized'.\"\n        },\n        {\n            \"question\": \"What is the purpose of the 'content' property in this CSS rule?\",\n            \"answer\": \"The 'content' property is set to an empty string.\",\n            \"explanation\": \"This means that no additional content, such as an emoji or text, will be displayed before the selected anchor elements, effectively preventing any visual output from the 'before' pseudo-element.\"\n        }\n    ]\n}"}, {"id": "2803a7e0-074b-4348-ac6f-cdb40a2eafb8", "input": "/* Minimized Taskbar Styling */\r\n.taskbar.minimized a {\r\n    display: flex;\r\n    align-items: center;  /* Center vertically */\r\n    justify-content: center;  /* Center horizontally */\r\n    width: 60px;\r\n    height: 60px;\r\n    padding: 0;\r\n    margin: 0;\r\n    box-sizing: border-box;\r\n}\r\n\r\n/* Icon within minimized taskbar */\r\n.taskbar.minimized a i {\r\n    font-size: 24px;  /* Adjust icon size */\r\n    line-height: 60px;  /* Match the button height to center vertically */\r\n    text-align: center;  /* Center horizontally */\r\n    width: 100%;  /* Make the icon fill the width of the button */\r\n    height: 100%;  /* Make the icon fill the height of the button */\r\n    margin: 0;  /* Remove extra margins */\r\n    padding: 0;  /* Remove extra padding */\r\n    display: block;  /* Block display ensures full width/height control */\r\n}\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What CSS properties are used to center elements in the minimized taskbar?\",\n            \"answer\": \"align-items: center; and justify-content: center;\",\n            \"explanation\": \"These properties are used in the flexbox layout to center child elements both vertically and horizontally within the parent container.\"\n        },\n        {\n            \"question\": \"What is the purpose of the 'box-sizing: border-box;' property in the minimized taskbar styling?\",\n            \"answer\": \"It ensures that padding and border are included in the element's total width and height.\",\n            \"explanation\": \"This property alters the box model so that the width and height you set for an element include its padding and border, making layout calculations more intuitive.\"\n        },\n        {\n            \"question\": \"How is the icon size adjusted in the minimized taskbar?\",\n            \"answer\": \"The icon size is adjusted using 'font-size: 24px;' and 'line-height: 60px;'.\",\n            \"explanation\": \"The font-size property sets the size of the icon, while line-height is set to match the button height to ensure vertical centering.\"\n        },\n        {\n            \"question\": \"What does 'display: block;' do for the icon in the minimized taskbar?\",\n            \"answer\": \"It ensures full control over the width and height of the icon.\",\n            \"explanation\": \"Using block display makes the icon take up the full width and height of its container, allowing for better alignment and sizing.\"\n        },\n        {\n            \"question\": \"What are the dimensions set for the minimized taskbar buttons?\",\n            \"answer\": \"The buttons have a width and height of 60px.\",\n            \"explanation\": \"This fixed size ensures that all buttons in the minimized taskbar are uniform and visually consistent.\"\n        }\n    ]\n}"}, {"id": "d2fd49ab-820d-411e-bffc-40760dccf780", "input": "Spurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation refers to a situation where data appears to be related but actually is not.\",\n            \"explanation\": \"In spurious correlation, the relationship between two variables is misleading, as they may be influenced by other factors or may simply coincide without any causal connection.\"\n        },\n        {\n            \"question\": \"What example is given to illustrate spurious correlation?\",\n            \"answer\": \"The example given is a cow being always in a green background.\",\n            \"explanation\": \"The illustration suggests that if an AI is trained to recognize a cow based on it being in a green background, it may incorrectly assume that an object in a different background is not a cow, highlighting how the correlation can lead to incorrect assumptions.\"\n        }\n    ]\n}"}, {"id": "2d178b68-2356-4071-bd72-c562ba6a12bf", "input": "Train/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is the purpose of splitting data into train, validation, and test sets?\",\n            \"answer\": \"To prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"By splitting the data, we can train the model on one set, validate its performance on another, and finally test it on a separate set to evaluate its effectiveness.\"\n        },\n        {\n            \"question\": \"What is the typical percentage of data used for the training set?\",\n            \"answer\": \"Usually 60-80% of the data.\",\n            \"explanation\": \"The training set is the largest portion of the data, allowing the model to learn the relationship between input features and the target output.\"\n        },\n        {\n            \"question\": \"What is the purpose of the validation set?\",\n            \"answer\": \"To select the best performing model during the training process.\",\n            \"explanation\": \"The validation set checks how well the model is performing and is usually a smaller portion of the data, typically 10-20%.\"\n        },\n        {\n            \"question\": \"What is the role of the test set in the model evaluation process?\",\n            \"answer\": \"To provide a final evaluation of the model's performance, used only once.\",\n            \"explanation\": \"The test set, which is also 10-20% of the data, helps assess how well the model performs on unseen data after training and validation.\"\n        },\n        {\n            \"question\": \"What important note is mentioned regarding the test set?\",\n            \"answer\": \"Never train on the test set; gauge performance on the validation set.\",\n            \"explanation\": \"Using the test set for training can lead to biased performance metrics, so it should only be used for final evaluation.\"\n        }\n    ]\n}"}, {"id": "b23c0c13-bcd4-4878-8f8f-8c608a8d1da3", "input": "Train/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is the purpose of splitting data into training, validation, and test sets?\",\n            \"answer\": \"To prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"Splitting the data helps in assessing the model's performance on different subsets, thereby reducing the likelihood of overfitting to the training data.\"\n        },\n        {\n            \"question\": \"What is the training set used for?\",\n            \"answer\": \"The training set is used to train the model.\",\n            \"explanation\": \"The model learns the relationship between input features and the target output variable using the training set, which typically comprises 60-80% of the data.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during training.\",\n            \"explanation\": \"It checks how well the model is performing and typically consists of a smaller portion of the data (10-20%), helping to fine-tune the model before final evaluation.\"\n        },\n        {\n            \"question\": \"What is the purpose of the test set?\",\n            \"answer\": \"The test set provides a final evaluation of the model.\",\n            \"explanation\": \"It is only used once and typically represents 10-20% of the data, ensuring that the model's performance is assessed on unseen data.\"\n        },\n        {\n            \"question\": \"What should never be done with the test set?\",\n            \"answer\": \"You should never train on the test set.\",\n            \"explanation\": \"Training on the test set would compromise its purpose of providing an unbiased evaluation of the model's performance.\"\n        }\n    ]\n}"}, {"id": "06c187fa-ed0e-47af-ba97-e6afb1c21e9d", "input": "Train/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is the purpose of splitting data into training, validation, and test sets?\",\n            \"answer\": \"To prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"By dividing the data, we can train the model on one set of data, validate its performance on another, and finally test it on a separate set to evaluate its effectiveness on unseen data.\"\n        },\n        {\n            \"question\": \"What is the training set used for?\",\n            \"answer\": \"The training set is used to train the model.\",\n            \"explanation\": \"It allows the model to learn the relationship between input variables (features) and the output variable (target), typically comprising 60-80% of the total data.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during training.\",\n            \"explanation\": \"It checks how well the model is performing and is usually a smaller portion of the data, around 10-20%.\"\n        },\n        {\n            \"question\": \"What is the purpose of the test set?\",\n            \"answer\": \"The test set provides a final evaluation of the model.\",\n            \"explanation\": \"It is only used once after the model has been trained and validated, typically comprising 10-20% of the data, to assess the model's performance on unseen data.\"\n        },\n        {\n            \"question\": \"What is a critical note regarding the test set?\",\n            \"answer\": \"You should never train on the test set.\",\n            \"explanation\": \"Training on the test set would compromise the integrity of the evaluation, as it would not provide a true measure of the model's performance on unseen data.\"\n        }\n    ]\n}"}, {"id": "4846f98a-9c3e-4a95-b8f1-40ac7caeb5ed", "input": "Train/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is the purpose of the Train/Validation/Test split?\",\n            \"answer\": \"To prevent overfitting and generalize well to new unseen data.\",\n            \"explanation\": \"The Train/Validation/Test split is a strategy used in machine learning to ensure that the model can generalize to new data rather than just memorizing the training data.\"\n        },\n        {\n            \"question\": \"What is the training set used for?\",\n            \"answer\": \"It is used to train the model to learn the relationship between features and the target.\",\n            \"explanation\": \"The training set consists of 60-80% of the data and is where the model learns to make predictions based on the input variables.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during training.\",\n            \"explanation\": \"Typically making up 10-20% of the data, the validation set helps in assessing the model's performance and fine-tuning it.\"\n        },\n        {\n            \"question\": \"What is the purpose of the test set?\",\n            \"answer\": \"The test set provides a final evaluation of the model's performance.\",\n            \"explanation\": \"It is only used once and accounts for 10-20% of the data, ensuring that the model's performance is assessed on unseen data.\"\n        },\n        {\n            \"question\": \"Why should you never train on the test set?\",\n            \"answer\": \"Training on the test set can lead to overfitting and an inaccurate assessment of model performance.\",\n            \"explanation\": \"The test set should only be used for final evaluation to ensure that the model's performance is genuinely reflective of its ability to generalize to new data.\"\n        }\n    ]\n}"}, {"id": "6aeb0ff0-648e-41a0-9a49-25b6e061057f", "input": "Train/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is the purpose of splitting data into training, validation, and test sets?\",\n            \"answer\": \"To prevent overfitting and to generalize well to new unseen data.\",\n            \"explanation\": \"The split helps ensure that the model does not just memorize the training data but can also perform well on new data.\"\n        },\n        {\n            \"question\": \"What is the training set used for?\",\n            \"answer\": \"It is used to train the model.\",\n            \"explanation\": \"The model learns the relationship between input features and the target output variable from the training set.\"\n        },\n        {\n            \"question\": \"What percentage of data is typically used for the training set?\",\n            \"answer\": \"Usually 60-80% of the data.\",\n            \"explanation\": \"This range allows a sufficient amount of data for the model to learn effectively.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"It is used to select the best performing model during training.\",\n            \"explanation\": \"The validation set checks how well the model is performing and helps in tuning model parameters.\"\n        },\n        {\n            \"question\": \"What percentage of data is typically allocated to the validation set?\",\n            \"answer\": \"10-20% of the data.\",\n            \"explanation\": \"This smaller portion allows for effective performance evaluation without taking too much data away from training.\"\n        },\n        {\n            \"question\": \"What is the purpose of the test set?\",\n            \"answer\": \"It provides a final evaluation of the model.\",\n            \"explanation\": \"The test set is used only once to assess how well the model performs on unseen data after training.\"\n        },\n        {\n            \"question\": \"What percentage of data is typically used for the test set?\",\n            \"answer\": \"10-20% of the data.\",\n            \"explanation\": \"This allocation allows for a reliable assessment of the model's performance while still reserving enough data for training and validation.\"\n        },\n        {\n            \"question\": \"What is a crucial note regarding the test set?\",\n            \"answer\": \"Never train on the test set.\",\n            \"explanation\": \"Training on the test set would lead to biased performance metrics, as the model would have seen the data it is being evaluated on.\"\n        }\n    ]\n}"}, {"id": "67e81317-3aca-4973-8526-5d89b6503196", "input": "Spurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\nScaling: \r\nneural networks (NN): takes in a list of numbers, outputs a list of numbers.\r\nkind of like a really complicated math function\r\nNNs scale very well - larger by adding more weights, learns data effectively\r\n\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is a spurious correlation?\",\n            \"answer\": \"A spurious correlation is when data appears to be related, but it isn't.\",\n            \"explanation\": \"An example provided is that a cow is always in a green background, but when it\u2019s in a different background, AI might assume it\u2019s not a cow, illustrating how misleading correlations can occur.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"The training set is used to train the model, the validation set helps select the best performing model, and the test set provides a final evaluation.\"\n        },\n        {\n            \"question\": \"What are the typical proportions of data allocated to training, validation, and test sets?\",\n            \"answer\": \"Usually, 60-80% of data is used for training, 10-20% for validation, and 10-20% for testing.\",\n            \"explanation\": \"This distribution helps in effective model training, selection, and evaluation.\"\n        },\n        {\n            \"question\": \"What is overfitting?\",\n            \"answer\": \"Overfitting occurs when a model is trained too well on the training data, causing it to perform poorly on new data.\",\n            \"explanation\": \"It can be identified by low training loss but high validation loss.\"\n        },\n        {\n            \"question\": \"What is underfitting?\",\n            \"answer\": \"Underfitting happens when a model cannot capture the underlying pattern of the data, leading to poor performance on all data.\",\n            \"explanation\": \"This indicates that the model is too simplistic or not trained adequately.\"\n        },\n        {\n            \"question\": \"How do neural networks scale?\",\n            \"answer\": \"Neural networks scale well by adding more weights and learning data effectively.\",\n            \"explanation\": \"They can take in a list of numbers and output a list of numbers, functioning like a complex mathematical function.\"\n        }\n    ]\n}"}, {"id": "3e9e0f8d-6035-4a77-9478-665c1387c69b", "input": "Spurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\nScaling: \r\nneural networks (NN): takes in a list of numbers, outputs a list of numbers.\r\nkind of like a really complicated math function\r\nNNs scale very well - larger by adding more weights, learns data effectively\r\n\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation occurs when data appears to be related but isn't.\",\n            \"explanation\": \"An example given is that a cow is always in a green background, but if it is in a different background, AI may incorrectly assume it is not a cow.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"The training set is used to train the model, the validation set is used to select the best performing model, and the test set is used for final evaluation.\"\n        },\n        {\n            \"question\": \"What are the typical proportions of data used for training, validation, and testing?\",\n            \"answer\": \"Training set: 60-80%, Validation set: 10-20%, Test set: 10-20%.\",\n            \"explanation\": \"These proportions help in effectively training the model while ensuring it can generalize to new data.\"\n        },\n        {\n            \"question\": \"What is overfitting?\",\n            \"answer\": \"Overfitting occurs when a model is trained too well, leading to poor performance on new data.\",\n            \"explanation\": \"It is characterized by low training loss and high validation loss.\"\n        },\n        {\n            \"question\": \"What is underfitting?\",\n            \"answer\": \"Underfitting occurs when a model cannot capture the pattern of the data, performing poorly on all data.\",\n            \"explanation\": \"It indicates that the model is too simple to learn the underlying relationships in the data.\"\n        },\n        {\n            \"question\": \"How do neural networks scale?\",\n            \"answer\": \"Neural networks scale well by adding more weights and effectively learning from data.\",\n            \"explanation\": \"They take in a list of numbers and output a list of numbers, functioning like complicated mathematical functions.\"\n        }\n    ]\n}"}, {"id": "ce1d4822-39d4-48ac-9de7-2a49daaa7bd8", "input": "Spurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\nScaling: \r\nneural networks (NN): takes in a list of numbers, outputs a list of numbers.\r\nkind of like a really complicated math function\r\nNNs scale very well - larger by adding more weights, learns data effectively\r\n\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"When data appears to be related, but isn\u2019t.\",\n            \"explanation\": \"An example is when a cow is always in a green background, leading AI to assume it's not a cow if it appears in a different background.\"\n        },\n        {\n            \"question\": \"What is the purpose of the Train/Validation/Test Split?\",\n            \"answer\": \"To prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"The training set is used to train the model, the validation set helps select the best model, and the test set provides final evaluation.\"\n        },\n        {\n            \"question\": \"What is the typical proportion of data used for the training set?\",\n            \"answer\": \"Usually 60-80% of the data.\",\n            \"explanation\": \"This portion is used to train the model to learn the relationship between features and the target.\"\n        },\n        {\n            \"question\": \"What are the characteristics of overfitting?\",\n            \"answer\": \"Trained too well, leading to poor performance on new data.\",\n            \"explanation\": \"It is indicated by low training loss and high validation loss.\"\n        },\n        {\n            \"question\": \"What is underfitting?\",\n            \"answer\": \"When a model cannot capture the pattern of the data.\",\n            \"explanation\": \"Underfitting results in poor performance on all data.\"\n        },\n        {\n            \"question\": \"How do neural networks (NN) scale?\",\n            \"answer\": \"They scale well by adding more weights and learn data effectively.\",\n            \"explanation\": \"Neural networks take in a list of numbers and output a list of numbers, functioning like a complicated math function.\"\n        }\n    ]\n}"}, {"id": "3b8e84d8-b437-49fd-a519-4e8245e57638", "input": "Spurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\nScaling: \r\nneural networks (NN): takes in a list of numbers, outputs a list of numbers.\r\nkind of like a really complicated math function\r\nNNs scale very well - larger by adding more weights, learns data effectively\r\n\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"When data appears to be related, but isn\u2019t.\",\n            \"explanation\": \"An example is when a cow is always in a green background, leading AI to assume it is not a cow when in a different background, despite the cow being the same.\"\n        },\n        {\n            \"question\": \"What is the purpose of the Train/Validation/Test Split?\",\n            \"answer\": \"To prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"The training set is used to teach the model, the validation set helps select the best model, and the test set provides a final evaluation.\"\n        },\n        {\n            \"question\": \"What is the typical distribution of data in Train/Validation/Test Split?\",\n            \"answer\": \"Usually 60-80% for training, 10-20% for validation, and 10-20% for testing.\",\n            \"explanation\": \"This distribution helps in effectively training the model while also validating and testing its performance.\"\n        },\n        {\n            \"question\": \"What is overfitting?\",\n            \"answer\": \"When a model is trained too well, causing it to perform poorly on new data.\",\n            \"explanation\": \"It can be identified by low training loss and high validation loss.\"\n        },\n        {\n            \"question\": \"What is underfitting?\",\n            \"answer\": \"When a model cannot capture the pattern of data, performing poorly on all data.\",\n            \"explanation\": \"Underfitting indicates that the model is too simple to learn the underlying structure of the data.\"\n        },\n        {\n            \"question\": \"How do neural networks (NN) function?\",\n            \"answer\": \"They take in a list of numbers and output a list of numbers.\",\n            \"explanation\": \"Neural networks can be thought of as complex mathematical functions that learn data effectively by scaling with more weights.\"\n        },\n        {\n            \"question\": \"What does it mean for neural networks to scale well?\",\n            \"answer\": \"They can become larger and learn data effectively by adding more weights.\",\n            \"explanation\": \"This ability to scale allows neural networks to handle more complex data and improve their learning capabilities.\"\n        }\n    ]\n}"}, {"id": "20544d5d-2c6a-4421-be47-189c37c15833", "input": "Spurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\nScaling: \r\nneural networks (NN): takes in a list of numbers, outputs a list of numbers.\r\nkind of like a really complicated math function\r\nNNs scale very well - larger by adding more weights, learns data effectively\r\n\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation occurs when data appears to be related, but actually isn't.\",\n            \"explanation\": \"An example is given where a cow is always in a green background; when the background changes, AI may incorrectly assume it's not a cow.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and to ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"The training set is used to train the model, the validation set helps select the best model, and the test set provides a final evaluation.\"\n        },\n        {\n            \"question\": \"What is the typical data distribution for training, validation, and test sets?\",\n            \"answer\": \"Training set: 60-80%, Validation set: 10-20%, Test set: 10-20%.\",\n            \"explanation\": \"This distribution helps ensure that the model is trained effectively while also being evaluated properly.\"\n        },\n        {\n            \"question\": \"What is overfitting?\",\n            \"answer\": \"Overfitting occurs when a model is trained too well on the training data, leading to poor performance on new data.\",\n            \"explanation\": \"It can be identified by low training loss and high validation loss.\"\n        },\n        {\n            \"question\": \"What is underfitting?\",\n            \"answer\": \"Underfitting happens when a model cannot capture the patterns in the data, resulting in poor performance on all data.\",\n            \"explanation\": \"This indicates that the model is too simple to learn from the data effectively.\"\n        },\n        {\n            \"question\": \"How do neural networks (NN) process data?\",\n            \"answer\": \"Neural networks take in a list of numbers and output a list of numbers.\",\n            \"explanation\": \"They function like complicated mathematical functions and can scale effectively by adding more weights to learn data.\"\n        }\n    ]\n}"}, {"id": "5dace661-4e82-44cf-9e67-1136931944d9", "input": "Spurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\nScaling: \r\nneural networks (NN): takes in a list of numbers, outputs a list of numbers.\r\nkind of like a really complicated math function\r\nNNs scale very well - larger by adding more weights, learns data effectively\r\n\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation is when data appears to be related, but it isn't.\",\n            \"explanation\": \"An example given is that a cow is always in a green background, but when placed in a different background, AI may incorrectly assume it is not a cow, highlighting the misleading nature of spurious correlations.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"The training set is used to train the model, the validation set is used to select the best performing model, and the test set provides a final evaluation.\"\n        },\n        {\n            \"question\": \"What is overfitting?\",\n            \"answer\": \"Overfitting occurs when a model is trained too well, causing it to perform poorly on new data.\",\n            \"explanation\": \"It is characterized by low training loss and high validation loss, indicating that the model has learned the training data too closely and fails to generalize.\"\n        },\n        {\n            \"question\": \"What is underfitting?\",\n            \"answer\": \"Underfitting happens when a model cannot capture the patterns of the data, leading to poor performance on all data.\",\n            \"explanation\": \"This indicates that the model is too simplistic and fails to learn from the training data effectively.\"\n        },\n        {\n            \"question\": \"How do neural networks scale?\",\n            \"answer\": \"Neural networks scale well by adding more weights and effectively learning from data.\",\n            \"explanation\": \"They take in a list of numbers and output a list of numbers, functioning similarly to a complicated mathematical function, allowing them to handle larger datasets.\"\n        }\n    ]\n}"}, {"id": "209ac4c1-e9ad-426d-b116-6725978d343b", "input": "Spurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\nScaling: \r\nneural networks (NN): takes in a list of numbers, outputs a list of numbers.\r\nkind of like a really complicated math function\r\nNNs scale very well - larger by adding more weights, learns data effectively\r\n\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"When data appears to be related but isn't.\",\n            \"explanation\": \"An example is a cow always being in a green background; if it's in a different background, AI might incorrectly assume it's not a cow.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"To prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"The training set is used to train the model, the validation set helps select the best model, and the test set provides a final evaluation.\"\n        },\n        {\n            \"question\": \"What is overfitting?\",\n            \"answer\": \"When a model is trained too well, causing it to perform poorly on new data.\",\n            \"explanation\": \"This can be identified by low training loss but high validation loss.\"\n        },\n        {\n            \"question\": \"What is underfitting?\",\n            \"answer\": \"When a model cannot capture the pattern of the data, performing poorly on all data.\",\n            \"explanation\": \"Underfitting indicates that the model is too simple to learn from the data.\"\n        },\n        {\n            \"question\": \"What do neural networks (NN) do?\",\n            \"answer\": \"They take in a list of numbers and output a list of numbers.\",\n            \"explanation\": \"Neural networks can be thought of as complicated math functions that learn data effectively by scaling with more weights.\"\n        }\n    ]\n}"}, {"id": "c3fa7ead-7fcf-4b50-ae94-27327a858a5a", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data instead of the underlying pattern, leading to poor performance on unseen data.\"\n        },\n        {\n            \"question\": \"What is a spurious correlation?\",\n            \"answer\": \"A spurious correlation is when data appears to be related, but there is no actual relationship.\",\n            \"explanation\": \"An example of spurious correlation is when a cow is always seen in a green background, leading AI to incorrectly assume that the background is a feature of being a cow.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure that the model generalizes well to new unseen data.\",\n            \"explanation\": \"This split allows the model to be trained on one set of data, validated on another to tune hyperparameters, and finally tested on a separate set for performance evaluation.\"\n        },\n        {\n            \"question\": \"What is the training set in the context of train/validation/test split?\",\n            \"answer\": \"The training set is used to train the model and usually comprises 60-80% of the data.\",\n            \"explanation\": \"In the training set, the model learns the relationship between input features and the target output.\"\n        },\n        {\n            \"question\": \"What role does the validation set play?\",\n            \"answer\": \"The validation set is used to select the best performing model during training and typically comprises 10-20% of the data.\",\n            \"explanation\": \"The validation set checks how well the model is performing and helps in tuning the model parameters.\"\n        },\n        {\n            \"question\": \"What is the function of the test set?\",\n            \"answer\": \"The test set provides a final evaluation of the model and is only used once.\",\n            \"explanation\": \"The test set, which also comprises 10-20% of the data, should never be used for training, as it is meant for assessing the model's performance after training and validation.\"\n        }\n    ]\n}"}, {"id": "bd06bca8-a00e-44ed-a2f0-192b84032fb4", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data rather than the underlying pattern, making it perform poorly on new, unseen data.\"\n        },\n        {\n            \"question\": \"What is a spurious correlation?\",\n            \"answer\": \"A spurious correlation is when data appears to be related but actually is not.\",\n            \"explanation\": \"An example is when a cow is always depicted in a green background; if the AI sees the cow in a different background, it may incorrectly assume it's not a cow, demonstrating a false relationship.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and to ensure the model generalizes well to unseen data.\",\n            \"explanation\": \"By splitting the data into training, validation, and test sets, we can train the model, tune it for performance, and finally evaluate it on a separate set that it has never seen before.\"\n        },\n        {\n            \"question\": \"What is the training set used for?\",\n            \"answer\": \"The training set is used to train the model by helping it learn the relationship between features and the target variable.\",\n            \"explanation\": \"Typically, the training set consists of 60-80% of the total data, allowing the model to learn effectively from a substantial amount of information.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during the training process.\",\n            \"explanation\": \"It checks how well the model is performing and usually comprises a smaller portion of the data (10-20%), helping to refine the model before final evaluation.\"\n        },\n        {\n            \"question\": \"What is the purpose of the test set?\",\n            \"answer\": \"The test set provides the final evaluation of the model's performance.\",\n            \"explanation\": \"It is used only once after the model has been trained and validated, ensuring an unbiased assessment of how the model will perform on new data.\"\n        },\n        {\n            \"question\": \"Why should you never train on the test set?\",\n            \"answer\": \"You should never train on the test set to ensure an unbiased evaluation of model performance.\",\n            \"explanation\": \"Training on the test set would lead to overfitting to that specific data, making the evaluation results misleading.\"\n        }\n    ]\n}"}, {"id": "d14f9e51-0355-4a78-b539-983504ade902", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\", \n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well to new data.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise and details of the training data to the extent that it negatively impacts the model's performance on unseen data.\"\n        },\n        {\n            \"question\": \"What is a spurious correlation?\", \n            \"answer\": \"A spurious correlation is when data appears to be related, but it is not.\",\n            \"explanation\": \"An example of spurious correlation is when a cow is always in a green background, leading an AI to incorrectly assume that a cow in a different background is not a cow.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\", \n            \"answer\": \"The purpose is to prevent overfitting and to ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"The split allows for a training set to learn relationships, a validation set to tune the model's performance, and a test set for final evaluation.\"\n        },\n        {\n            \"question\": \"What is the typical size of the training set in a train/validation/test split?\", \n            \"answer\": \"The training set usually comprises 60-80% of the data.\",\n            \"explanation\": \"This portion is used to train the model and helps it learn the relationship between input features and output targets.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\", \n            \"answer\": \"The validation set is used to select the best performing model during the training process.\",\n            \"explanation\": \"It checks how well the model performs on a smaller portion of data (10-20%) and helps in tuning the model parameters.\"\n        },\n        {\n            \"question\": \"When is the test set used in the machine learning process?\", \n            \"answer\": \"The test set is used for final evaluation and is only used once.\",\n            \"explanation\": \"It typically comprises 10-20% of the data and provides an unbiased evaluation of the model's performance after training and validation.\"\n        },\n        {\n            \"question\": \"Why should you never train on the test set?\", \n            \"answer\": \"You should never train on the test set to ensure an unbiased evaluation of the model's performance.\",\n            \"explanation\": \"Training on the test set would lead to overfitting and an inaccurate assessment of how the model performs on unseen data.\"\n        }\n    ]\n}"}, {"id": "3609c52f-5df1-47a0-9c8c-7ada2ad74e98", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise and details in the training data to the extent that it negatively impacts the model's performance on new data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation is when data appears to be related, but there is no actual relationship.\",\n            \"explanation\": \"An example is when a cow is always in a green background, leading AI to incorrectly assume that the background color is related to whether it is a cow or not.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"By splitting the data into these three sets, we can effectively train the model, validate its performance, and finally test its accuracy on unseen data.\"\n        },\n        {\n            \"question\": \"What is the training set used for?\",\n            \"answer\": \"The training set is used to train the model by learning the relationship between features and the target variable.\",\n            \"explanation\": \"Typically comprising 60-80% of the data, the training set allows the model to adjust its parameters based on the input-output relationships.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during the training process.\",\n            \"explanation\": \"It checks how well the model is performing and usually consists of a smaller portion of the data (10-20%).\"\n        },\n        {\n            \"question\": \"What is the purpose of the test set?\",\n            \"answer\": \"The test set provides a final evaluation of the model's performance.\",\n            \"explanation\": \"It is only used once and typically comprises 10-20% of the data, ensuring that the model's performance is assessed on completely unseen data.\"\n        },\n        {\n            \"question\": \"What should never be done with the test set?\",\n            \"answer\": \"You should never train on the test set.\",\n            \"explanation\": \"Training on the test set can lead to overfitting and an inaccurate assessment of the model's performance, as it would have already seen the data.\"\n        }\n    ]\n}"}, {"id": "064ef671-e1e1-41d6-a10e-effc75c42389", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data rather than the actual underlying patterns, leading to poor performance on unseen data.\"\n        },\n        {\n            \"question\": \"What is a spurious correlation?\",\n            \"answer\": \"A spurious correlation is when data appears to be related, but there is no actual relationship.\",\n            \"explanation\": \"An example is when a cow is always in a green background; if the AI assumes a cow is not present in a different background, it demonstrates a misunderstanding of the data.\"\n        },\n        {\n            \"question\": \"What is the purpose of splitting data into training, validation, and test sets?\",\n            \"answer\": \"The purpose is to prevent overfitting and to ensure the model generalizes well to new, unseen data.\",\n            \"explanation\": \"By separating the data, the model can be trained on one set, validated on another, and finally tested on a third set to assess its performance.\"\n        },\n        {\n            \"question\": \"What is the training set used for?\",\n            \"answer\": \"The training set is used to train the model, allowing it to learn the relationship between features and the target variable.\",\n            \"explanation\": \"Typically, the training set comprises 60-80% of the total data, providing enough examples for the model to learn from.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during the training process.\",\n            \"explanation\": \"This smaller portion of data (10-20%) helps check how well the model is performing and aids in tuning hyperparameters.\"\n        },\n        {\n            \"question\": \"What is the purpose of the test set?\",\n            \"answer\": \"The test set provides a final evaluation of the model's performance.\",\n            \"explanation\": \"It is only used once after the model has been trained and validated, ensuring an unbiased assessment of how well the model generalizes.\"\n        },\n        {\n            \"question\": \"What is a key note regarding the test set?\",\n            \"answer\": \"You should never train on the test set.\",\n            \"explanation\": \"Training on the test set would lead to biased results, as the model would have already seen this data, making it essential to gauge performance solely on the validation set.\"\n        }\n    ]\n}"}, {"id": "fa3eb637-add8-45ae-b1bb-ef767fb47a97", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data instead of the underlying pattern, making it perform poorly on unseen data.\"\n        },\n        {\n            \"question\": \"What is a spurious correlation?\",\n            \"answer\": \"A spurious correlation is when data appears to be related, but there is no actual relationship.\",\n            \"explanation\": \"An example is a cow always being in a green background; if the model learns this correlation, it may incorrectly identify a cow when it is in a different background.\"\n        },\n        {\n            \"question\": \"What are the three splits in data for machine learning?\",\n            \"answer\": \"The three splits are training set, validation set, and test set.\",\n            \"explanation\": \"The training set is used to train the model, the validation set is used to select the best model during training, and the test set is used for final evaluation.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"By splitting the data into these sets, we can train the model, validate its performance, and then test it without bias.\"\n        },\n        {\n            \"question\": \"How much of the data is typically used for the training set?\",\n            \"answer\": \"Typically, 60-80% of the data is used for the training set.\",\n            \"explanation\": \"This portion is used to allow the model to learn the relationship between features and the target variable.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during the training process.\",\n            \"explanation\": \"It checks how well the model is performing on a smaller portion of data, usually 10-20%.\"\n        },\n        {\n            \"question\": \"What is the test set used for?\",\n            \"answer\": \"The test set provides a final evaluation of the model.\",\n            \"explanation\": \"The test set is only used once to assess the model's performance and should not be used for training.\"\n        },\n        {\n            \"question\": \"Can you train the model on the test set?\",\n            \"answer\": \"No, you should never train on the test set.\",\n            \"explanation\": \"Training on the test set would bias the evaluation, making it unreliable.\"\n        }\n    ]\n}"}, {"id": "71f6352f-1420-4e4f-9d47-3e839e381573", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise and details of the training data to the extent that it negatively impacts the performance of the model on new data.\"\n        },\n        {\n            \"question\": \"What is a spurious correlation?\",\n            \"answer\": \"A spurious correlation is when data appears to be related, but there is no actual relationship.\",\n            \"explanation\": \"An example of spurious correlation is when a cow is always in a green background, leading an AI to incorrectly assume that the background is necessary for identifying the cow.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"By splitting the data into these three sets, we can train the model, tune its parameters, and evaluate its performance without bias.\"\n        },\n        {\n            \"question\": \"What is the training set?\",\n            \"answer\": \"The training set is used to train the model, allowing it to learn the relationship between features and the target variable.\",\n            \"explanation\": \"Typically, the training set comprises 60-80% of the total data, enabling the model to learn effectively.\"\n        },\n        {\n            \"question\": \"What is the validation set used for?\",\n            \"answer\": \"The validation set is used to select the best performing model during the training process.\",\n            \"explanation\": \"It checks how well the model is performing on a smaller portion of the data, usually 10-20%, allowing for model tuning.\"\n        },\n        {\n            \"question\": \"What is the test set and how is it used?\",\n            \"answer\": \"The test set provides a final evaluation of the model and is only used once.\",\n            \"explanation\": \"It typically constitutes 10-20% of the data and should never be used for training; it serves to gauge the model's performance after training and validation.\"\n        }\n    ]\n}"}, {"id": "a3d8296d-df9a-4f36-84e6-a49800d3f45d", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise and details in the training data to the extent that it negatively impacts the performance on new, unseen data.\"\n        },\n        {\n            \"question\": \"What is a spurious correlation?\",\n            \"answer\": \"A spurious correlation is when data appears to be related but is not actually related.\",\n            \"explanation\": \"An example is when a model assumes that a cow is not a cow simply because it appears in a different background, despite the fact that the cow's identity is independent of the background.\"\n        },\n        {\n            \"question\": \"What is the purpose of splitting data into training, validation, and test sets?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"By using different subsets of data for training, validating, and testing, we can better evaluate the model's performance and ability to generalize.\"\n        },\n        {\n            \"question\": \"What is the training set?\",\n            \"answer\": \"The training set is used to train the model and usually comprises 60-80% of the data.\",\n            \"explanation\": \"In the training set, the model learns the relationship between the input features and the target output variable.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during training and typically consists of 10-20% of the data.\",\n            \"explanation\": \"The validation set helps evaluate how well the model is performing and aids in model selection without using the test set.\"\n        },\n        {\n            \"question\": \"What is the purpose of the test set?\",\n            \"answer\": \"The test set provides a final evaluation of the model and is only used once.\",\n            \"explanation\": \"The test set, which also comprises 10-20% of the data, is used to assess the model's performance after training and validation are complete.\"\n        },\n        {\n            \"question\": \"Why should you never train on the test set?\",\n            \"answer\": \"You should never train on the test set to ensure an unbiased evaluation of the model's performance.\",\n            \"explanation\": \"Training on the test set can lead to overfitting to that specific data, rendering the performance metrics unreliable.\"\n        }\n    ]\n}"}, {"id": "08889380-0769-40cc-9ae3-994516c955b7", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data instead of the underlying pattern, leading to poor performance on unseen data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation is when data appears to be related but is not actually related.\",\n            \"explanation\": \"An example of spurious correlation is when an AI assumes a cow is not a cow if it is in a different background, despite the fact that the background does not affect its identity.\"\n        },\n        {\n            \"question\": \"What is the purpose of splitting data into training, validation, and test sets?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new, unseen data.\",\n            \"explanation\": \"By using distinct datasets for training, validation, and testing, we can evaluate the model's performance accurately and avoid bias in performance metrics.\"\n        },\n        {\n            \"question\": \"What is the training set in machine learning?\",\n            \"answer\": \"The training set is used to train the model and typically comprises 60-80% of the data.\",\n            \"explanation\": \"In the training set, the model learns the relationship between the input variables (features) and the output variable (target).\"\n        },\n        {\n            \"question\": \"What is the purpose of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during the training process.\",\n            \"explanation\": \"It checks how well the model is performing and usually consists of a smaller portion of the data (10-20%).\"\n        },\n        {\n            \"question\": \"What is the test set used for?\",\n            \"answer\": \"The test set provides a final evaluation of the model and is only used once.\",\n            \"explanation\": \"The test set typically comprises 10-20% of the data and should never be used for training to ensure an unbiased assessment of model performance.\"\n        },\n        {\n            \"question\": \"What is a key note regarding the test set?\",\n            \"answer\": \"Never train on the test set; performance should be gauged on the validation set.\",\n            \"explanation\": \"Using the test set for training can lead to overfitting and an inaccurate representation of how the model will perform on unseen data.\"\n        }\n    ]\n}"}, {"id": "a011097f-bcdf-4b9a-acfb-669e6e91c870", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data rather than the intended outputs, making it perform poorly on unseen data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation is when data appears to be related, but there is no actual relationship.\",\n            \"explanation\": \"An example is a cow being always in a green background; if the AI sees a cow in a different background, it might incorrectly assume it\u2019s not a cow due to the perceived correlation.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"By splitting the data, the model can be trained on one set, validated on another, and tested on a third to gauge its performance accurately.\"\n        },\n        {\n            \"question\": \"What is the training set?\",\n            \"answer\": \"The training set is used to train the model, allowing it to learn the relationship between features and the target variable.\",\n            \"explanation\": \"Typically, this set comprises 60-80% of the data, enabling the model to learn effectively.\"\n        },\n        {\n            \"question\": \"What is the validation set used for?\",\n            \"answer\": \"The validation set is used to select the best performing model during training.\",\n            \"explanation\": \"This smaller portion of data (10-20%) checks how well the model is performing and helps in tuning the model parameters.\"\n        },\n        {\n            \"question\": \"What is the test set?\",\n            \"answer\": \"The test set provides the final evaluation of the model and is used only once.\",\n            \"explanation\": \"Comprising 10-20% of the data, it is crucial for assessing the model's performance after training and validation.\"\n        },\n        {\n            \"question\": \"Why should you never train on the test set?\",\n            \"answer\": \"You should never train on the test set to ensure an unbiased evaluation of the model's performance.\",\n            \"explanation\": \"Training on the test set would lead to overfitting to that specific data, making the performance evaluation unreliable.\"\n        }\n    ]\n}"}, {"id": "19d645bb-83b6-440a-830d-8efcd9262795", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model captures noise and details in the training data to the extent that it negatively impacts its performance on new, unseen data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation occurs when data appears to be related, but there is no actual relationship.\",\n            \"explanation\": \"An example is a cow always being in a green background; if the AI assumes it\u2019s not a cow when in a different background, it demonstrates how spurious correlations can lead to incorrect assumptions.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new, unseen data.\",\n            \"explanation\": \"By splitting the data into training, validation, and test sets, we can train the model, select the best model, and evaluate performance without biasing the results.\"\n        },\n        {\n            \"question\": \"What is the training set?\",\n            \"answer\": \"The training set is used to train the model and typically consists of 60-80% of the data.\",\n            \"explanation\": \"In the training set, the model learns the relationship between input variables (features) and output variables (targets).\"\n        },\n        {\n            \"question\": \"What is the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during the training process and usually comprises 10-20% of the data.\",\n            \"explanation\": \"It helps check how well the model is performing and is crucial for tuning hyperparameters and preventing overfitting.\"\n        },\n        {\n            \"question\": \"What is the test set?\",\n            \"answer\": \"The test set provides a final evaluation of the model and is only used once, typically comprising 10-20% of the data.\",\n            \"explanation\": \"It is important to never train on the test set, as it is meant to give an unbiased evaluation of the model's performance after training and validation.\"\n        }\n    ]\n}"}, {"id": "2287e264-38f2-43ad-b9e7-5d713811d02c", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data instead of the underlying pattern, making it perform poorly on unseen data.\"\n        },\n        {\n            \"question\": \"What is a spurious correlation?\",\n            \"answer\": \"A spurious correlation is when data appears to be related, but there is no actual relationship.\",\n            \"explanation\": \"An example is a cow always being in a green background; if the AI assumes it's not a cow when the background changes, it demonstrates spurious correlation.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new, unseen data.\",\n            \"explanation\": \"By splitting the data into training, validation, and test sets, we can train the model, tune its performance, and evaluate it without bias.\"\n        },\n        {\n            \"question\": \"What is the training set used for?\",\n            \"answer\": \"The training set is used to train the model and learn the relationship between features and the target variable.\",\n            \"explanation\": \"Typically, the training set comprises 60-80% of the data, allowing the model to learn patterns from a substantial amount of examples.\"\n        },\n        {\n            \"question\": \"What role does the validation set play?\",\n            \"answer\": \"The validation set is used to select the best performing model during the training process.\",\n            \"explanation\": \"It checks how well the model is performing and usually consists of a smaller portion of the data (10-20%).\"\n        },\n        {\n            \"question\": \"What is the purpose of the test set?\",\n            \"answer\": \"The test set provides a final evaluation of the model's performance.\",\n            \"explanation\": \"It is only used once after training and validation, typically making up 10-20% of the data, to assess how well the model generalizes.\"\n        },\n        {\n            \"question\": \"What should you never do with the test set?\",\n            \"answer\": \"You should never train on the test set.\",\n            \"explanation\": \"Training on the test set would bias the evaluation, as the model would have already seen that data, leading to misleading performance metrics.\"\n        }\n    ]\n}"}, {"id": "f92d2490-2c67-492a-8746-2c7f4ac1c567", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data instead of the underlying pattern, leading to poor performance on unseen data.\"\n        },\n        {\n            \"question\": \"What is a spurious correlation?\",\n            \"answer\": \"A spurious correlation is when data appears to be related, but there is no actual relationship.\",\n            \"explanation\": \"An example is when an AI assumes a cow is not a cow because it is in a different background, despite the background having no real impact on the cow's identity.\"\n        },\n        {\n            \"question\": \"What is the purpose of splitting data into training, validation, and test sets?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new, unseen data.\",\n            \"explanation\": \"By using separate sets for training, validation, and testing, we can evaluate the model's performance and fine-tune it without biasing the results.\"\n        },\n        {\n            \"question\": \"What is the training set in machine learning?\",\n            \"answer\": \"The training set is used to train the model and typically consists of 60-80% of the data.\",\n            \"explanation\": \"It allows the model to learn the relationship between input features and the target output.\"\n        },\n        {\n            \"question\": \"What is the validation set used for?\",\n            \"answer\": \"The validation set is used to select the best performing model during training, typically comprising 10-20% of the data.\",\n            \"explanation\": \"It helps in assessing how well the model performs and in tuning its parameters without using the test set.\"\n        },\n        {\n            \"question\": \"What is the role of the test set?\",\n            \"answer\": \"The test set provides a final evaluation of the model's performance and is only used once.\",\n            \"explanation\": \"It ensures that the model's performance is assessed on completely unseen data, providing an unbiased evaluation.\"\n        },\n        {\n            \"question\": \"Why should you never train on the test set?\",\n            \"answer\": \"You should never train on the test set to avoid biasing the performance evaluation.\",\n            \"explanation\": \"Training on the test set would lead to overfitting on that specific data, rendering the evaluation meaningless.\"\n        }\n    ]\n}"}, {"id": "2e145363-caf5-4eed-8563-c0514214c18f", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data instead of the actual underlying patterns, making it perform poorly on unseen data.\"\n        },\n        {\n            \"question\": \"What is a spurious correlation?\",\n            \"answer\": \"A spurious correlation is when data appears to be related but is not.\",\n            \"explanation\": \"An example is when an AI assumes a cow is not a cow if it's in a different background, even though the background does not determine whether it is a cow.\"\n        },\n        {\n            \"question\": \"What are the three main data splits in machine learning?\",\n            \"answer\": \"The three main data splits are training set, validation set, and test set.\",\n            \"explanation\": \"The training set is used to train the model, the validation set is used to tune the model's parameters, and the test set is used for final evaluation.\"\n        },\n        {\n            \"question\": \"What is the purpose of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during the training process.\",\n            \"explanation\": \"It checks how well the model is performing and helps to prevent overfitting by ensuring the model generalizes well to new data.\"\n        },\n        {\n            \"question\": \"What is the recommended percentage of data for the training set?\",\n            \"answer\": \"The training set typically consists of 60-80% of the total data.\",\n            \"explanation\": \"This proportion allows the model to learn effectively while leaving enough data for validation and testing.\"\n        },\n        {\n            \"question\": \"Why should you never train on the test set?\",\n            \"answer\": \"You should never train on the test set to ensure an unbiased evaluation of the model's performance.\",\n            \"explanation\": \"Using the test set for training would lead to overfitting on that specific data, making the performance metrics unreliable.\"\n        }\n    ]\n}"}, {"id": "acc360ea-c2cc-4ab5-84e0-ae428798a262", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, leading to a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the details and noise in the training data to the extent that it negatively impacts the performance of the model on new data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation occurs when data appears to be related, but there is no actual relationship.\",\n            \"explanation\": \"An example is when a cow is always in a green background, and the AI mistakenly assumes that the background is a factor in identifying the cow, leading to incorrect conclusions when the cow is in a different background.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"By splitting the data into training, validation, and test sets, we can train the model, tune it, and finally evaluate its performance on unseen data.\"\n        },\n        {\n            \"question\": \"What is the training set used for?\",\n            \"answer\": \"The training set is used to train the model and learn the relationship between features and target.\",\n            \"explanation\": \"Typically comprising 60-80% of the data, the training set allows the model to identify patterns and relationships within the data.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during training.\",\n            \"explanation\": \"It checks how well the model is performing and typically consists of a smaller portion of the data (10-20%), helping to fine-tune the model.\"\n        },\n        {\n            \"question\": \"What is the test set used for?\",\n            \"answer\": \"The test set provides a final evaluation of the model's performance.\",\n            \"explanation\": \"It is only used once after the model has been trained and validated, and typically makes up 10-20% of the data.\"\n        },\n        {\n            \"question\": \"Why should the test set not be used for training?\",\n            \"answer\": \"The test set should not be used for training to ensure an unbiased evaluation of the model's performance.\",\n            \"explanation\": \"Using the test set for training could lead to overfitting and an inaccurate assessment of how the model will perform on unseen data.\"\n        }\n    ]\n}"}, {"id": "e7f8e872-f53d-4540-ac7f-9123e293cf9a", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns not only the underlying patterns but also the noise in the training data, making it perform poorly on unseen data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation is when data appears to be related, but there is actually no true relationship.\",\n            \"explanation\": \"An example of spurious correlation is if a cow is always photographed in a green background; the AI might incorrectly assume that the green background is a feature of cows, leading to misclassification when the background changes.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"By splitting the data into training, validation, and test sets, we can train the model on one portion, tune it on another, and evaluate its performance on a completely separate set.\"\n        },\n        {\n            \"question\": \"What is the training set used for?\",\n            \"answer\": \"The training set is used to train the model, allowing it to learn the relationship between features and the target variable.\",\n            \"explanation\": \"Typically comprising 60-80% of the data, the training set helps the model understand the patterns necessary for making predictions.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during the training process.\",\n            \"explanation\": \"It checks how well the model performs on a smaller portion of the data (10-20%), helping to prevent overfitting by allowing adjustments to be made before final evaluation.\"\n        },\n        {\n            \"question\": \"What is the test set used for?\",\n            \"answer\": \"The test set provides a final evaluation of the model's performance.\",\n            \"explanation\": \"Only used once, the test set (10-20% of the data) helps to assess how well the model generalizes to new, unseen data, ensuring that training and validation processes do not influence the results.\"\n        },\n        {\n            \"question\": \"Why should you never train on the test set?\",\n            \"answer\": \"You should never train on the test set to ensure an unbiased evaluation of the model's performance.\",\n            \"explanation\": \"Training on the test set would lead to overfitting to that specific data, making the performance metrics unreliable and not reflective of the model's true capabilities on unseen data.\"\n        }\n    ]\n}"}, {"id": "95c520de-ea06-4fbe-8605-acfdab79a217", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data rather than the underlying patterns, making it perform poorly on unseen data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation is when data appears to be related, but there is no actual relationship.\",\n            \"explanation\": \"An example is a cow that is always in a green background; if the AI assumes it\u2019s not a cow when in a different background, it highlights how misleading correlations can lead to incorrect assumptions.\"\n        },\n        {\n            \"question\": \"What are the three sets used in the Train/Validation/Test Split?\",\n            \"answer\": \"The three sets are the training set, validation set, and test set.\",\n            \"explanation\": \"The training set is used to train the model, the validation set is used to select the best model during training, and the test set is used for final evaluation.\"\n        },\n        {\n            \"question\": \"What percentage of the data is typically used for the training set?\",\n            \"answer\": \"Typically, 60-80% of the data is used for the training set.\",\n            \"explanation\": \"The training set should contain a significant portion of the data to allow the model to learn effectively.\"\n        },\n        {\n            \"question\": \"What is the purpose of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during the training process.\",\n            \"explanation\": \"It helps check how well the model is performing on a smaller portion of data, usually 10-20%.\"\n        },\n        {\n            \"question\": \"What is the purpose of the test set?\",\n            \"answer\": \"The test set provides a final evaluation of the model and is used only once.\",\n            \"explanation\": \"It is crucial that the test set is not used for training to ensure an unbiased evaluation of the model's performance.\"\n        },\n        {\n            \"question\": \"Why should you never train on the test set?\",\n            \"answer\": \"You should never train on the test set to maintain an unbiased measure of the model's performance.\",\n            \"explanation\": \"Training on the test set can lead to overfitting and an inaccurate assessment of how well the model will perform on unseen data.\"\n        }\n    ]\n}"}, {"id": "a5b9737d-5ba0-4633-8c95-36fe1c9e4943", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is when a model fits too closely to the training data and fails to generalize well to new unseen data.\",\n            \"explanation\": \"Overfitting is undesirable because it means the model may perform well on the training data but poorly on new data, limiting its practical application.\"\n        },\n        {\n            \"question\": \"What is a spurious correlation?\",\n            \"answer\": \"A spurious correlation is when two variables appear to be related, but they are not actually connected.\",\n            \"explanation\": \"An example is when a cow is always in a green background, leading AI to incorrectly assume that the background is a defining feature of a cow.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure that the model generalizes well to new unseen data.\",\n            \"explanation\": \"By dividing the data into training, validation, and test sets, we can train the model, tune its parameters, and evaluate its performance without bias.\"\n        },\n        {\n            \"question\": \"What is the training set used for?\",\n            \"answer\": \"The training set is used to train the model by teaching it the relationship between input features and output targets.\",\n            \"explanation\": \"Typically, the training set comprises 60-80% of the data, allowing the model to learn effectively from a substantial amount of information.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during the training process.\",\n            \"explanation\": \"It checks how well the model is performing and usually consists of a smaller portion of the data (10-20%), helping to tune the model without using the test set.\"\n        },\n        {\n            \"question\": \"What is the purpose of the test set?\",\n            \"answer\": \"The test set provides a final evaluation of the model's performance.\",\n            \"explanation\": \"It is only used once after the model has been trained and validated, typically comprising 10-20% of the data, ensuring an unbiased assessment of the model.\"\n        },\n        {\n            \"question\": \"What should never be done with the test set?\",\n            \"answer\": \"You should never train on the test set.\",\n            \"explanation\": \"Training on the test set can lead to biased performance results, as the model would have already seen the data it is being evaluated on.\"\n        }\n    ]\n}"}, {"id": "584b6913-925e-4a94-a669-9a8befe31fa4", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data and not providing a more general result.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data instead of the underlying pattern, leading to poor generalization on new data.\"\n        },\n        {\n            \"question\": \"What is a spurious correlation?\",\n            \"answer\": \"A spurious correlation is when data appears to be related, but it is not.\",\n            \"explanation\": \"An example of spurious correlation is when a cow is always in a green background, leading AI to incorrectly assume it is not a cow if it is in a different background.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"By splitting the data into training, validation, and test sets, we can train the model, tune its performance, and evaluate it without bias.\"\n        },\n        {\n            \"question\": \"What is the training set used for?\",\n            \"answer\": \"The training set is used to train the model by learning the relationship between features and the target variable.\",\n            \"explanation\": \"Typically, the training set comprises 60-80% of the data, allowing the model to understand how input variables relate to the output variable.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during training.\",\n            \"explanation\": \"It checks how well the model is performing and usually consists of a smaller portion of data (10-20%) to prevent overfitting.\"\n        },\n        {\n            \"question\": \"What is the purpose of the test set?\",\n            \"answer\": \"The test set provides a final evaluation of the model and is only used once.\",\n            \"explanation\": \"The test set, which is also 10-20% of the data, helps gauge the model's performance after training and validation without bias from previous data.\"\n        },\n        {\n            \"question\": \"Why should you never train on the test set?\",\n            \"answer\": \"You should never train on the test set to avoid bias in performance evaluation.\",\n            \"explanation\": \"Training on the test set would lead to overfitting, as the model would have already seen the data it is being evaluated on, skewing the results.\"\n        }\n    ]\n}"}, {"id": "c0e41661-70bd-4147-b9b9-3c9d215092e5", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data instead of the actual pattern, leading to poor performance on unseen data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation is when data appears to be related, but there is no actual relationship.\",\n            \"explanation\": \"An example is a cow always being in a green background; if the AI sees a cow in a different background, it may incorrectly assume it is not a cow, illustrating the danger of misleading correlations.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"By splitting data into training, validation, and test sets, we can train the model, tune its performance, and evaluate it without bias.\"\n        },\n        {\n            \"question\": \"What is the training set used for?\",\n            \"answer\": \"The training set is used to train the model, allowing it to learn the relationship between features and the target variable.\",\n            \"explanation\": \"Typically comprising 60-80% of the data, the training set enables the model to adjust its parameters based on the input-output relationship.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during training.\",\n            \"explanation\": \"It checks how well the model performs on unseen data and usually consists of a smaller portion of data (10-20%).\"\n        },\n        {\n            \"question\": \"What does the test set provide?\",\n            \"answer\": \"The test set provides a final evaluation of the model's performance.\",\n            \"explanation\": \"Used only once, the test set (also 10-20% of data) assesses how well the model generalizes to new data after training and validation.\"\n        },\n        {\n            \"question\": \"Why should you never train on the test set?\",\n            \"answer\": \"Training on the test set can lead to biased performance metrics.\",\n            \"explanation\": \"The test set should remain unseen during the training process to provide an unbiased evaluation of the model's performance.\"\n        }\n    ]\n}"}, {"id": "a7a94cba-e8ec-40b4-b4f4-2a06460b4c21", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well to new data.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data rather than the underlying patterns, making it perform poorly on unseen data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation is when data appears to be related but is not actually correlated.\",\n            \"explanation\": \"An example is a cow always being in a green background; if the AI assumes it is not a cow when in a different background, it demonstrates spurious correlation.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"By splitting the data into these sets, we can effectively train the model, validate its performance, and test its final evaluation.\"\n        },\n        {\n            \"question\": \"What are the typical proportions of data used for training, validation, and testing?\",\n            \"answer\": \"Training set: 60-80%, Validation set: 10-20%, Test set: 10-20%.\",\n            \"explanation\": \"These proportions help to balance the need for training the model while still having enough data to validate and test its performance.\"\n        },\n        {\n            \"question\": \"What is the difference between overfitting and underfitting?\",\n            \"answer\": \"Overfitting occurs when a model is trained too well on the training data, while underfitting occurs when a model fails to capture the patterns in the data.\",\n            \"explanation\": \"Overfitting leads to low training loss but high validation loss, whereas underfitting results in poor performance across all data.\"\n        },\n        {\n            \"question\": \"How can you tell if a model is overfitting?\",\n            \"answer\": \"You can tell if a model is overfitting by observing low training loss and high validation loss.\",\n            \"explanation\": \"This indicates that the model has learned the training data too well but is not performing well on the validation set, suggesting it may not generalize.\"\n        }\n    ]\n}"}, {"id": "c3762711-0a50-4da9-9d85-01f40143bb24", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, leading to poor generalization.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data instead of the underlying pattern, making it perform poorly on new, unseen data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation is when data appears to be related but is not.\",\n            \"explanation\": \"An example is a cow always being in a green background; if the AI sees a cow in a different background, it may incorrectly assume it's not a cow, demonstrating a false relationship.\"\n        },\n        {\n            \"question\": \"What is the purpose of the Train/Validation/Test split?\",\n            \"answer\": \"To prevent overfitting and to ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"The training set is used to train the model, the validation set helps select the best model during training, and the test set provides a final evaluation.\"\n        },\n        {\n            \"question\": \"What is the typical percentage of data used for the training set?\",\n            \"answer\": \"Usually 60-80% of the data.\",\n            \"explanation\": \"The training set is the largest portion of the data, allowing the model to learn the relationships between features and the target variable.\"\n        },\n        {\n            \"question\": \"What is the difference between overfitting and underfitting?\",\n            \"answer\": \"Overfitting is when a model is trained too well and performs poorly on new data; underfitting is when a model cannot capture the patterns of the data.\",\n            \"explanation\": \"Overfitting results in low training loss but high validation loss, while underfitting leads to poor performance across all data.\"\n        },\n        {\n            \"question\": \"How can you tell if a model is overfitting?\",\n            \"answer\": \"By observing low training loss and high validation loss.\",\n            \"explanation\": \"This indicates that while the model fits the training data well, it fails to generalize to the validation data.\"\n        }\n    ]\n}"}, {"id": "146bc69f-4964-4298-bf7a-e132a258dd85", "input": "for each term listed, provide a flashcard with term and definition:\r\n6. Concrete Language: Language that describes specific, observable things, people, or places, rather than ideas or qualities.\r\n\r\nRhetorical Devices: Syntax\r\n7. Phrase: A small group of words standing together as a conceptual unit, typically forming a component of a clause.\r\n8. Clause: A unit of grammatical organization that consists of a subject and predicate and forms part of a sentence or a whole sentence.\r\n9. Sentence Fragment: A group of words that is punctuated as a sentence but does not express a complete thought.\r\n10. Periodic Sentence: A sentence that has the main clause or predicate at the end, often used for emphasis or to create suspense.\r\n11. Cumulative Sentence: A sentence that begins with an independent clause and then adds subordinate elements or modifiers.\r\n12. Balanced Sentence: A sentence made up of two parts that are roughly equal in length, importance, and grammatical structure.\r\n13. Parallelism: The use of successive verbal constructions in poetry or prose that correspond in grammatical structure, sound, meter, meaning, etc.\r\n14. Antithesis: A rhetorical device in which two opposite ideas are put together in a sentence to achieve a contrasting effect.\r\n15. Chiasmus: A rhetorical or literary figure in which words, grammatical constructions, or concepts are repeated in reverse order.\r\n16. Anaphora: The repetition of a word or phrase at the beginning of successive clauses.\r\n17. Epistrophe: The repetition of a word at the end of successive clauses or sentences.\r\n24. Metonymy: The substitution of the name of an attribute or adjunct for that of the thing meant.\r\n25. Synecdoche: A figure of speech in which a part is made to represent the whole or vice versa.\r\n26. Irony: The expression of one's meaning by using language that normally signifies the opposite, typically for humorous or emphatic effect.\r\n27. Euphemism: A mild or indirect word or expression substituted for one considered to be too harsh or blunt when referring to something unpleasant or embarrassing.\r\n28. Paradox: A statement that contradicts itself but might be true.\r\n29. Epithet: An adjective or descriptive phrase expressing a quality characteristic of the person or thing mentioned.\r\n33. Narration: The action or process of narrating a story.\r\n34. Definition: A statement of the exact meaning of a word, especially in a dictionary.\r\n35. Classification: The action or process of classifying something according to shared qualities or characteristics.\r\n36. Description: A spoken or written representation or account of a person, object, or event.\r\n37. Process Analysis: A method of paragraph or essay development by which a writer explains step by step how something is done or how to do something.\r\n38. Exemplification: Providing examples to illustrate a point.\r\n40. Comparison/Contrast: A rhetorical mode that discusses the similarities and differences between two or more things.\r\n41. Analysis: The detailed examination of the elements or structure of something, typically as a basis for discussion or interpretation.\r\n42. Cause and Effect: A rhetorical mode that explains why things happen (the cause) and what happens as a result (the effect).\r\n46. Induction: A method of reasoning that moves from specific instances to a general conclusion.\r\n47. Deduction: A method of reasoning from the general to the specific.\r\n48. Syllogism: A form of reasoning in which a conclusion is drawn from two given or assumed propositions.\r\n49. Enthymeme: A syllogism in which one of the premises is implied rather than stated.\r\n50. Analogy: A comparison between two things, typically for the purpose of explanation or clarification.\r\n51. Qualify/Qualifier: To qualify is to modify or limit in some way, making a statement less absolute. A qualifier is a word or phrase that limits or modifies the meaning of another word or phrase.\r\n52. Concession: An acknowledgment of the other side's argument or a point made by an opponent.\r\n53. Rebuttal: A counterargument, especially in debate.\r\n55. Either/Or: A logical fallacy that presents only two options or sides when there are many possible choices.\r\n56. False Analogy: A logical fallacy that occurs when an analogy compares two things that are not comparable.\r\n57. Circular Reasoning: A logical fallacy in which the reasoner begins with what they are trying to end with.\r\n58. Single Cause Fallacy: A logical fallacy that occurs when it is assumed that there is one simple cause of an outcome when there may be many causes.\r\n59. Post hoc, ergo propter hoc: A logical fallacy that assumes that because one event happened after another, it must have been caused by the first event.\r\n60. Vague or Undefined Terms: A logical fallacy where the terms used are unclear or undefined.\r\n61. Unreliable Testimonial: A fallacy in which a claim is supported by an unreliable or unqualified source.\r\n62. Equivocation: A logical fallacy that involves using an ambiguous term in more than one sense, making the argument misleading.\r\n63. Transfer: A propaganda technique in which positive or negative feelings from one thing are associated with another unrelated thing.\r\n64. Bandwagon: A fallacy based on the assumption that the opinion of the majority is always valid.\r\n65. Snob Appeal: A fallacy in which something is argued to be good because it is elite, special, or rare.\r\n66. Loaded Words: Words that are emotionally charged to influence the audience's perception.\r\n67. Literal / Figurative: Literal language means exactly what it says, while figurative language uses similes, metaphors, etc.\r\n68. Clich\u00e9: A phrase or opinion that is overused and lacks original thought.\r\n69. Aphorism: A pithy observation that contains a general truth.\r\n70. Subjective / Objective: Subjective is based on personal opinions; objective is based on verifiable facts.\r\n71. Allegory: A story, poem, or picture that reveals a hidden meaning, typically moral or political.\r\n72. Epigram: A pithy saying or remark expressing an idea in a clever and amusing way.\r\n73. Satire: The use of humor, irony, or ridicule to expose and criticize people's stupidity or vices.\r\n74. Parody: An imitation of a style with deliberate exaggeration for comic effect.\r\n75. Colloquial: Language used in ordinary conversation; informal.\r\n76. Exigence: The reason or situation that prompts someone to write or speak; an urgent need or demand that causes the creation of a text.\r\n\r\n\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is Concrete Language?\",\n            \"answer\": \"Language that describes specific, observable things, people, or places.\",\n            \"explanation\": \"Concrete language focuses on tangible and specific details rather than abstract ideas or qualities.\"\n        },\n        {\n            \"question\": \"What is a Phrase?\",\n            \"answer\": \"A small group of words standing together as a conceptual unit, typically forming a component of a clause.\",\n            \"explanation\": \"A phrase does not contain a subject and a verb, and it functions as a single unit within a sentence.\"\n        },\n        {\n            \"question\": \"What defines a Clause?\",\n            \"answer\": \"A unit of grammatical organization that consists of a subject and predicate.\",\n            \"explanation\": \"Clauses can be independent (able to stand alone as a sentence) or dependent (cannot stand alone).\"\n        },\n        {\n            \"question\": \"What is a Sentence Fragment?\",\n            \"answer\": \"A group of words that is punctuated as a sentence but does not express a complete thought.\",\n            \"explanation\": \"Sentence fragments often lack a subject or verb, making them incomplete.\"\n        },\n        {\n            \"question\": \"What is a Periodic Sentence?\",\n            \"answer\": \"A sentence that has the main clause or predicate at the end.\",\n            \"explanation\": \"Periodic sentences are often used for emphasis or to create suspense.\"\n        },\n        {\n            \"question\": \"What is a Cumulative Sentence?\",\n            \"answer\": \"A sentence that begins with an independent clause and then adds subordinate elements or modifiers.\",\n            \"explanation\": \"Cumulative sentences provide additional information after the main idea.\"\n        },\n        {\n            \"question\": \"What is a Balanced Sentence?\",\n            \"answer\": \"A sentence made up of two parts that are roughly equal in length, importance, and grammatical structure.\",\n            \"explanation\": \"Balanced sentences often create a rhythm and symmetry in writing.\"\n        },\n        {\n            \"question\": \"What is Parallelism?\",\n            \"answer\": \"The use of successive verbal constructions that correspond in grammatical structure.\",\n            \"explanation\": \"Parallelism enhances clarity and rhythm in writing.\"\n        },\n        {\n            \"question\": \"What is Antithesis?\",\n            \"answer\": \"A rhetorical device in which two opposite ideas are put together in a sentence.\",\n            \"explanation\": \"Antithesis highlights contrasts and can create a powerful effect.\"\n        },\n        {\n            \"question\": \"What is Chiasmus?\",\n            \"answer\": \"A rhetorical figure in which words or concepts are repeated in reverse order.\",\n            \"explanation\": \"Chiasmus can create a memorable and impactful statement.\"\n        },\n        {\n            \"question\": \"What is Anaphora?\",\n            \"answer\": \"The repetition of a word or phrase at the beginning of successive clauses.\",\n            \"explanation\": \"Anaphora is often used to emphasize a point or create a rhythm.\"\n        },\n        {\n            \"question\": \"What is Epistrophe?\",\n            \"answer\": \"The repetition of a word at the end of successive clauses or sentences.\",\n            \"explanation\": \"Epistrophe creates a sense of closure and emphasis.\"\n        },\n        {\n            \"question\": \"What is Metonymy?\",\n            \"answer\": \"The substitution of the name of an attribute or adjunct for that of the thing meant.\",\n            \"explanation\": \"Metonymy allows for a more vivid and indirect way of referring to something.\"\n        },\n        {\n            \"question\": \"What is Synecdoche?\",\n            \"answer\": \"A figure of speech in which a part is made to represent the whole or vice versa.\",\n            \"explanation\": \"Synecdoche is often used to create a deeper connection with the subject.\"\n        },\n        {\n            \"question\": \"What is Irony?\",\n            \"answer\": \"The expression of one's meaning by using language that normally signifies the opposite.\",\n            \"explanation\": \"Irony is often used for humorous or emphatic effect.\"\n        },\n        {\n            \"question\": \"What is a Euphemism?\",\n            \"answer\": \"A mild or indirect word or expression substituted for one considered too harsh.\",\n            \"explanation\": \"Euphemisms soften the impact of unpleasant or embarrassing subjects.\"\n        },\n        {\n            \"question\": \"What is a Paradox?\",\n            \"answer\": \"A statement that contradicts itself but might be true.\",\n            \"explanation\": \"Paradoxes often provoke thought and challenge conventional wisdom.\"\n        },\n        {\n            \"question\": \"What is an Epithet?\",\n            \"answer\": \"An adjective or descriptive phrase expressing a quality characteristic of the person or thing mentioned.\",\n            \"explanation\": \"Epithets enrich the description and provide insight into the nature of the subject.\"\n        },\n        {\n            \"question\": \"What is Narration?\",\n            \"answer\": \"The action or process of narrating a story.\",\n            \"explanation\": \"Narration involves telling a story or recounting events.\"\n        },\n        {\n            \"question\": \"What is a Definition?\",\n            \"answer\": \"A statement of the exact meaning of a word, especially in a dictionary.\",\n            \"explanation\": \"Definitions clarify the meaning of terms and concepts.\"\n        },\n        {\n            \"question\": \"What is Classification?\",\n            \"answer\": \"The action or process of classifying something according to shared qualities.\",\n            \"explanation\": \"Classification helps organize information and identify relationships.\"\n        },\n        {\n            \"question\": \"What is Description?\",\n            \"answer\": \"A spoken or written representation or account of a person, object, or event.\",\n            \"explanation\": \"Descriptions provide detailed imagery and context.\"\n        },\n        {\n            \"question\": \"What is Process Analysis?\",\n            \"answer\": \"A method of paragraph or essay development by which a writer explains how something is done.\",\n            \"explanation\": \"Process analysis breaks down steps into clear, understandable parts.\"\n        },\n        {\n            \"question\": \"What is Exemplification?\",\n            \"answer\": \"Providing examples to illustrate a point.\",\n            \"explanation\": \"Exemplification strengthens arguments by offering concrete evidence.\"\n        },\n        {\n            \"question\": \"What is Comparison/Contrast?\",\n            \"answer\": \"A rhetorical mode that discusses the similarities and differences between two or more things.\",\n            \"explanation\": \"This mode helps clarify relationships and distinctions.\"\n        },\n        {\n            \"question\": \"What is Analysis?\",\n            \"answer\": \"The detailed examination of the elements or structure of something.\",\n            \"explanation\": \"Analysis is crucial for understanding and interpreting texts.\"\n        },\n        {\n            \"question\": \"What is Cause and Effect?\",\n            \"answer\": \"A rhetorical mode that explains why things happen (the cause) and what happens as a result (the effect).\",\n            \"explanation\": \"Cause and effect relationships help in understanding events and their outcomes.\"\n        },\n        {\n            \"question\": \"What is Induction?\",\n            \"answer\": \"A method of reasoning that moves from specific instances to a general conclusion.\",\n            \"explanation\": \"Induction is used to form generalizations based on observed patterns.\"\n        },\n        {\n            \"question\": \"What is Deduction?\",\n            \"answer\": \"A method of reasoning from the general to the specific.\",\n            \"explanation\": \"Deduction applies general principles to specific cases.\"\n        },\n        {\n            \"question\": \"What is Syllogism?\",\n            \"answer\": \"A form of reasoning in which a conclusion is drawn from two given or assumed propositions.\",\n            \"explanation\": \"Syllogism is a logical structure that helps in forming valid arguments.\"\n        },\n        {\n            \"question\": \"What is an Enthymeme?\",\n            \"answer\": \"A syllogism in which one of the premises is implied rather than stated.\",\n            \"explanation\": \"Enthymemes rely on the audience's ability to fill in the gaps.\"\n        },\n        {\n            \"question\": \"What is an Analogy?\",\n            \"answer\": \"A comparison between two things, typically for the purpose of explanation or clarification.\",\n            \"explanation\": \"Analogies help simplify complex ideas by relating them to familiar concepts.\"\n        },\n        {\n            \"question\": \"What does it mean to Qualify/Qualifier?\",\n            \"answer\": \"To qualify is to modify or limit in some way; a qualifier modifies the meaning of another word.\",\n            \"explanation\": \"Qualifiers add nuance and precision to statements.\"\n        },\n        {\n            \"question\": \"What is a Concession?\",\n            \"answer\": \"An acknowledgment of the other side's argument or a point made by an opponent.\",\n            \"explanation\": \"Concessions show understanding and can strengthen one's own argument.\"\n        },\n        {\n            \"question\": \"What is a Rebuttal?\",\n            \"answer\": \"A counterargument, especially in debate.\",\n            \"explanation\": \"Rebuttals are crucial for challenging opposing viewpoints.\"\n        },\n        {\n            \"question\": \"What is Either/Or?\",\n            \"answer\": \"A logical fallacy that presents only two options when there are many possible choices.\",\n            \"explanation\": \"This fallacy oversimplifies complex issues.\"\n        },\n        {\n            \"question\": \"What is a False Analogy?\",\n            \"answer\": \"A logical fallacy that compares two things that are not comparable.\",\n            \"explanation\": \"False analogies can mislead by creating false equivalences.\"\n        },\n        {\n            \"question\": \"What is Circular Reasoning?\",\n            \"answer\": \"A logical fallacy in which the reasoner begins with what they are trying to end with.\",\n            \"explanation\": \"Circular reasoning fails to provide valid support for an argument.\"\n        },\n        {\n            \"question\": \"What is a Single Cause Fallacy?\",\n            \"answer\": \"A logical fallacy that assumes there is one simple cause of an outcome.\",\n            \"explanation\": \"This fallacy ignores the complexity of causation.\"\n        },\n        {\n            \"question\": \"What does Post hoc, ergo propter hoc mean?\",\n            \"answer\": \"A logical fallacy that assumes that because one event happened after another, it must have been caused by the first event.\",\n            \"explanation\": \"This fallacy overlooks other potential causes.\"\n        },\n        {\n            \"question\": \"What are Vague or Undefined Terms?\",\n            \"answer\": \"A logical fallacy where the terms used are unclear or undefined.\",\n            \"explanation\": \"Vague terms can lead to confusion and misinterpretation.\"\n        },\n        {\n            \"question\": \"What is an Unreliable Testimonial?\",\n            \"answer\": \"A fallacy in which a claim is supported by an unreliable or unqualified source.\",\n            \"explanation\": \"Unreliable testimonials undermine the credibility of an argument.\"\n        },\n        {\n            \"question\": \"What is Equivocation?\",\n            \"answer\": \"A logical fallacy that involves using an ambiguous term in more than one sense.\",\n            \"explanation\": \"Equivocation can mislead by exploiting the ambiguity of language.\"\n        },\n        {\n            \"question\": \"What is Transfer?\",\n            \"answer\": \"A propaganda technique in which positive or negative feelings from one thing are associated with another unrelated thing.\",\n            \"explanation\": \"Transfer aims to manipulate perceptions through emotional associations.\"\n        },\n        {\n            \"question\": \"What is Bandwagon?\",\n            \"answer\": \"A fallacy based on the assumption that the opinion of the majority is always valid.\",\n            \"explanation\": \"Bandwagon appeals to popularity rather than logic.\"\n        },\n        {\n            \"question\": \"What is Snob Appeal?\",\n            \"answer\": \"A fallacy in which something is argued to be good because it is elite, special, or rare.\",\n            \"explanation\": \"Snob appeal relies on social status rather than intrinsic value.\"\n        },\n        {\n            \"question\": \"What are Loaded Words?\",\n            \"answer\": \"Words that are emotionally charged to influence the audience's perception.\",\n            \"explanation\": \"Loaded words can evoke strong emotional responses.\"\n        },\n        {\n            \"question\": \"What is the difference between Literal and Figurative language?\",\n            \"answer\": \"Literal language means exactly what it says, while figurative language uses similes, metaphors, etc.\",\n            \"explanation\": \"Understanding the distinction is crucial for interpreting texts accurately.\"\n        },\n        {\n            \"question\": \"What is a Clich\u00e9?\",\n            \"answer\": \"A phrase or opinion that is overused and lacks original thought.\",\n            \"explanation\": \"Clich\u00e9s can weaken writing by lacking freshness and creativity.\"\n        },\n        {\n            \"question\": \"What is an Aphorism?\",\n            \"answer\": \"A pithy observation that contains a general truth.\",\n            \"explanation\": \"Aphorisms often convey wisdom in a concise manner.\"\n        },\n        {\n            \"question\": \"What is the difference between Subjective and Objective?\",\n            \"answer\": \"Subjective is based on personal opinions; objective is based on verifiable facts.\",\n            \"explanation\": \"This distinction is important for critical thinking and analysis.\"\n        },\n        {\n            \"question\": \"What is an Allegory?\",\n            \"answer\": \"A story, poem, or picture that reveals a hidden meaning, typically moral or political.\",\n            \"explanation\": \"Allegories use symbolic figures and actions to convey deeper meanings.\"\n        },\n        {\n            \"question\": \"What is an Epigram?\",\n            \"answer\": \"A pithy saying or remark expressing an idea in a clever and amusing way.\",\n            \"explanation\": \"Epigrams are often witty and thought-provoking.\"\n        },\n        {\n            \"question\": \"What is Satire?\",\n            \"answer\": \"The use of humor, irony, or ridicule to expose and criticize people's stupidity or vices.\",\n            \"explanation\": \"Satire aims to provoke thought and inspire change through criticism.\"\n        },\n        {\n            \"question\": \"What is a Parody?\",\n            \"answer\": \"An imitation of a style with deliberate exaggeration for comic effect.\",\n            \"explanation\": \"Parody highlights the characteristics of the original work in a humorous way.\"\n        },\n        {\n            \"question\": \"What does Colloquial mean?\",\n            \"answer\": \"Language used in ordinary conversation; informal.\",\n            \"explanation\": \"Colloquial language reflects everyday speech and can vary by region.\"\n        },\n        {\n            \"question\": \"What is Exigence?\",\n            \"answer\": \"The reason or situation that prompts someone to write or speak.\",\n            \"explanation\": \"Exigence is the driving force behind the creation of a text.\"\n        }\n    ]\n}"}, {"id": "514e8497-ec51-4e87-aa3e-bf1774eb9053", "input": "for each term listed, provide a flashcard with term and definition:\r\n6. Concrete Language: Language that describes specific, observable things, people, or places, rather than ideas or qualities.\r\n\r\nRhetorical Devices: Syntax\r\n7. Phrase: A small group of words standing together as a conceptual unit, typically forming a component of a clause.\r\n8. Clause: A unit of grammatical organization that consists of a subject and predicate and forms part of a sentence or a whole sentence.\r\n9. Sentence Fragment: A group of words that is punctuated as a sentence but does not express a complete thought.\r\n10. Periodic Sentence: A sentence that has the main clause or predicate at the end, often used for emphasis or to create suspense.\r\n11. Cumulative Sentence: A sentence that begins with an independent clause and then adds subordinate elements or modifiers.\r\n12. Balanced Sentence: A sentence made up of two parts that are roughly equal in length, importance, and grammatical structure.\r\n13. Parallelism: The use of successive verbal constructions in poetry or prose that correspond in grammatical structure, sound, meter, meaning, etc.\r\n14. Antithesis: A rhetorical device in which two opposite ideas are put together in a sentence to achieve a contrasting effect.\r\n15. Chiasmus: A rhetorical or literary figure in which words, grammatical constructions, or concepts are repeated in reverse order.\r\n16. Anaphora: The repetition of a word or phrase at the beginning of successive clauses.\r\n17. Epistrophe: The repetition of a word at the end of successive clauses or sentences.\r\n24. Metonymy: The substitution of the name of an attribute or adjunct for that of the thing meant.\r\n25. Synecdoche: A figure of speech in which a part is made to represent the whole or vice versa.\r\n26. Irony: The expression of one's meaning by using language that normally signifies the opposite, typically for humorous or emphatic effect.\r\n27. Euphemism: A mild or indirect word or expression substituted for one considered to be too harsh or blunt when referring to something unpleasant or embarrassing.\r\n28. Paradox: A statement that contradicts itself but might be true.\r\n29. Epithet: An adjective or descriptive phrase expressing a quality characteristic of the person or thing mentioned.\r\n33. Narration: The action or process of narrating a story.\r\n34. Definition: A statement of the exact meaning of a word, especially in a dictionary.\r\n35. Classification: The action or process of classifying something according to shared qualities or characteristics.\r\n36. Description: A spoken or written representation or account of a person, object, or event.\r\n37. Process Analysis: A method of paragraph or essay development by which a writer explains step by step how something is done or how to do something.\r\n38. Exemplification: Providing examples to illustrate a point.\r\n40. Comparison/Contrast: A rhetorical mode that discusses the similarities and differences between two or more things.\r\n41. Analysis: The detailed examination of the elements or structure of something, typically as a basis for discussion or interpretation.\r\n42. Cause and Effect: A rhetorical mode that explains why things happen (the cause) and what happens as a result (the effect).\r\n46. Induction: A method of reasoning that moves from specific instances to a general conclusion.\r\n47. Deduction: A method of reasoning from the general to the specific.\r\n48. Syllogism: A form of reasoning in which a conclusion is drawn from two given or assumed propositions.\r\n49. Enthymeme: A syllogism in which one of the premises is implied rather than stated.\r\n50. Analogy: A comparison between two things, typically for the purpose of explanation or clarification.\r\n51. Qualify/Qualifier: To qualify is to modify or limit in some way, making a statement less absolute. A qualifier is a word or phrase that limits or modifies the meaning of another word or phrase.\r\n52. Concession: An acknowledgment of the other side's argument or a point made by an opponent.\r\n53. Rebuttal: A counterargument, especially in debate.\r\n55. Either/Or: A logical fallacy that presents only two options or sides when there are many possible choices.\r\n56. False Analogy: A logical fallacy that occurs when an analogy compares two things that are not comparable.\r\n57. Circular Reasoning: A logical fallacy in which the reasoner begins with what they are trying to end with.\r\n58. Single Cause Fallacy: A logical fallacy that occurs when it is assumed that there is one simple cause of an outcome when there may be many causes.\r\n59. Post hoc, ergo propter hoc: A logical fallacy that assumes that because one event happened after another, it must have been caused by the first event.\r\n60. Vague or Undefined Terms: A logical fallacy where the terms used are unclear or undefined.\r\n61. Unreliable Testimonial: A fallacy in which a claim is supported by an unreliable or unqualified source.\r\n62. Equivocation: A logical fallacy that involves using an ambiguous term in more than one sense, making the argument misleading.\r\n63. Transfer: A propaganda technique in which positive or negative feelings from one thing are associated with another unrelated thing.\r\n64. Bandwagon: A fallacy based on the assumption that the opinion of the majority is always valid.\r\n65. Snob Appeal: A fallacy in which something is argued to be good because it is elite, special, or rare.\r\n66. Loaded Words: Words that are emotionally charged to influence the audience's perception.\r\n67. Literal / Figurative: Literal language means exactly what it says, while figurative language uses similes, metaphors, etc.\r\n68. Clich\u00e9: A phrase or opinion that is overused and lacks original thought.\r\n69. Aphorism: A pithy observation that contains a general truth.\r\n70. Subjective / Objective: Subjective is based on personal opinions; objective is based on verifiable facts.\r\n71. Allegory: A story, poem, or picture that reveals a hidden meaning, typically moral or political.\r\n72. Epigram: A pithy saying or remark expressing an idea in a clever and amusing way.\r\n73. Satire: The use of humor, irony, or ridicule to expose and criticize people's stupidity or vices.\r\n74. Parody: An imitation of a style with deliberate exaggeration for comic effect.\r\n75. Colloquial: Language used in ordinary conversation; informal.\r\n76. Exigence: The reason or situation that prompts someone to write or speak; an urgent need or demand that causes the creation of a text.\r\n\r\n\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is Concrete Language?\",\n            \"answer\": \"Language that describes specific, observable things, people, or places.\",\n            \"explanation\": \"Concrete language focuses on tangible, measurable elements rather than abstract ideas or qualities.\"\n        },\n        {\n            \"question\": \"What is a Phrase?\",\n            \"answer\": \"A small group of words standing together as a conceptual unit, typically forming a component of a clause.\",\n            \"explanation\": \"Phrases are essential building blocks in sentence structure that convey a single idea.\"\n        },\n        {\n            \"question\": \"What is a Clause?\",\n            \"answer\": \"A unit of grammatical organization that consists of a subject and predicate.\",\n            \"explanation\": \"Clauses can function as standalone sentences or as parts of larger sentences.\"\n        },\n        {\n            \"question\": \"What is a Sentence Fragment?\",\n            \"answer\": \"A group of words that is punctuated as a sentence but does not express a complete thought.\",\n            \"explanation\": \"Sentence fragments lack the necessary components to form a complete idea, making them grammatically incorrect.\"\n        },\n        {\n            \"question\": \"What is a Periodic Sentence?\",\n            \"answer\": \"A sentence that has the main clause or predicate at the end.\",\n            \"explanation\": \"Periodic sentences build suspense or emphasis by delaying the main idea until the end.\"\n        },\n        {\n            \"question\": \"What is a Cumulative Sentence?\",\n            \"answer\": \"A sentence that begins with an independent clause and then adds subordinate elements or modifiers.\",\n            \"explanation\": \"Cumulative sentences allow for additional details to be added after the main idea.\"\n        },\n        {\n            \"question\": \"What is a Balanced Sentence?\",\n            \"answer\": \"A sentence made up of two parts that are roughly equal in length, importance, and grammatical structure.\",\n            \"explanation\": \"Balanced sentences create a sense of symmetry and can enhance the clarity of the message.\"\n        },\n        {\n            \"question\": \"What is Parallelism?\",\n            \"answer\": \"The use of successive verbal constructions that correspond in grammatical structure.\",\n            \"explanation\": \"Parallelism can create rhythm and make passages easier to read and understand.\"\n        },\n        {\n            \"question\": \"What is Antithesis?\",\n            \"answer\": \"A rhetorical device in which two opposite ideas are put together in a sentence.\",\n            \"explanation\": \"Antithesis highlights contrasts and can enhance the persuasive power of the argument.\"\n        },\n        {\n            \"question\": \"What is Chiasmus?\",\n            \"answer\": \"A rhetorical or literary figure in which words or concepts are repeated in reverse order.\",\n            \"explanation\": \"Chiasmus creates a memorable structure and emphasizes the relationship between ideas.\"\n        },\n        {\n            \"question\": \"What is Anaphora?\",\n            \"answer\": \"The repetition of a word or phrase at the beginning of successive clauses.\",\n            \"explanation\": \"Anaphora is used to create a rhythm and reinforce a point in writing or speech.\"\n        },\n        {\n            \"question\": \"What is Epistrophe?\",\n            \"answer\": \"The repetition of a word at the end of successive clauses or sentences.\",\n            \"explanation\": \"Epistrophe emphasizes a particular idea by repeating it at the conclusion of phrases.\"\n        },\n        {\n            \"question\": \"What is Metonymy?\",\n            \"answer\": \"The substitution of the name of an attribute or adjunct for that of the thing meant.\",\n            \"explanation\": \"Metonymy allows for more vivid and relatable descriptions by using associated terms.\"\n        },\n        {\n            \"question\": \"What is Synecdoche?\",\n            \"answer\": \"A figure of speech in which a part is made to represent the whole or vice versa.\",\n            \"explanation\": \"Synecdoche can create a more intimate connection to the subject by focusing on a specific part.\"\n        },\n        {\n            \"question\": \"What is Irony?\",\n            \"answer\": \"The expression of one's meaning by using language that normally signifies the opposite.\",\n            \"explanation\": \"Irony can be humorous or emphatic, highlighting contradictions in situations or statements.\"\n        },\n        {\n            \"question\": \"What is a Euphemism?\",\n            \"answer\": \"A mild or indirect word or expression substituted for one considered too harsh.\",\n            \"explanation\": \"Euphemisms soften the impact of unpleasant topics and can make communication more palatable.\"\n        },\n        {\n            \"question\": \"What is a Paradox?\",\n            \"answer\": \"A statement that contradicts itself but might be true.\",\n            \"explanation\": \"Paradoxes provoke thought and illustrate complex truths or situations.\"\n        },\n        {\n            \"question\": \"What is an Epithet?\",\n            \"answer\": \"An adjective or descriptive phrase expressing a quality characteristic of the person or thing mentioned.\",\n            \"explanation\": \"Epithets add depth and characterization, enhancing the reader's understanding.\"\n        },\n        {\n            \"question\": \"What is Narration?\",\n            \"answer\": \"The action or process of narrating a story.\",\n            \"explanation\": \"Narration involves telling a story, conveying events in a structured manner.\"\n        },\n        {\n            \"question\": \"What is a Definition?\",\n            \"answer\": \"A statement of the exact meaning of a word, especially in a dictionary.\",\n            \"explanation\": \"Definitions clarify the meaning of terms, aiding comprehension and communication.\"\n        },\n        {\n            \"question\": \"What is Classification?\",\n            \"answer\": \"The action or process of classifying something according to shared qualities.\",\n            \"explanation\": \"Classification organizes information, making it easier to understand and analyze.\"\n        },\n        {\n            \"question\": \"What is Description?\",\n            \"answer\": \"A spoken or written representation or account of a person, object, or event.\",\n            \"explanation\": \"Descriptions provide detailed imagery, helping readers visualize the subject matter.\"\n        },\n        {\n            \"question\": \"What is Process Analysis?\",\n            \"answer\": \"A method of paragraph or essay development explaining step by step how something is done.\",\n            \"explanation\": \"Process analysis breaks down complex tasks into manageable steps for clarity.\"\n        },\n        {\n            \"question\": \"What is Exemplification?\",\n            \"answer\": \"Providing examples to illustrate a point.\",\n            \"explanation\": \"Exemplification strengthens arguments by offering concrete instances.\"\n        },\n        {\n            \"question\": \"What is Comparison/Contrast?\",\n            \"answer\": \"A rhetorical mode that discusses the similarities and differences between two or more things.\",\n            \"explanation\": \"Comparison/contrast enhances understanding by highlighting relationships between subjects.\"\n        },\n        {\n            \"question\": \"What is Analysis?\",\n            \"answer\": \"The detailed examination of the elements or structure of something.\",\n            \"explanation\": \"Analysis is essential for interpretation and understanding the deeper meanings of texts.\"\n        },\n        {\n            \"question\": \"What is Cause and Effect?\",\n            \"answer\": \"A rhetorical mode that explains why things happen (the cause) and what happens as a result (the effect).\",\n            \"explanation\": \"This mode helps to clarify relationships between events and their outcomes.\"\n        },\n        {\n            \"question\": \"What is Induction?\",\n            \"answer\": \"A method of reasoning that moves from specific instances to a general conclusion.\",\n            \"explanation\": \"Induction allows for generalizations based on observed patterns or examples.\"\n        },\n        {\n            \"question\": \"What is Deduction?\",\n            \"answer\": \"A method of reasoning from the general to the specific.\",\n            \"explanation\": \"Deduction applies general principles to reach specific conclusions.\"\n        },\n        {\n            \"question\": \"What is Syllogism?\",\n            \"answer\": \"A form of reasoning in which a conclusion is drawn from two given propositions.\",\n            \"explanation\": \"Syllogisms provide a logical framework for making deductions.\"\n        },\n        {\n            \"question\": \"What is an Enthymeme?\",\n            \"answer\": \"A syllogism in which one of the premises is implied rather than stated.\",\n            \"explanation\": \"Enthymemes rely on the audience's ability to fill in the gaps in reasoning.\"\n        },\n        {\n            \"question\": \"What is an Analogy?\",\n            \"answer\": \"A comparison between two things, typically for the purpose of explanation or clarification.\",\n            \"explanation\": \"Analogies help to illustrate complex ideas by relating them to familiar concepts.\"\n        },\n        {\n            \"question\": \"What does it mean to Qualify/Qualifier?\",\n            \"answer\": \"To qualify is to modify or limit in some way; a qualifier is a word that limits or modifies meaning.\",\n            \"explanation\": \"Qualifiers add nuance to statements, making them less absolute.\"\n        },\n        {\n            \"question\": \"What is a Concession?\",\n            \"answer\": \"An acknowledgment of the other side's argument or a point made by an opponent.\",\n            \"explanation\": \"Concessions demonstrate understanding and can strengthen one's own argument.\"\n        },\n        {\n            \"question\": \"What is a Rebuttal?\",\n            \"answer\": \"A counterargument, especially in debate.\",\n            \"explanation\": \"Rebuttals are critical for defending one's position against opposing views.\"\n        },\n        {\n            \"question\": \"What is Either/Or?\",\n            \"answer\": \"A logical fallacy that presents only two options when there are many possible choices.\",\n            \"explanation\": \"This fallacy oversimplifies complex issues by limiting perspectives.\"\n        },\n        {\n            \"question\": \"What is a False Analogy?\",\n            \"answer\": \"A logical fallacy that compares two things that are not comparable.\",\n            \"explanation\": \"False analogies can mislead by drawing inappropriate parallels.\"\n        },\n        {\n            \"question\": \"What is Circular Reasoning?\",\n            \"answer\": \"A logical fallacy in which the reasoner begins with what they are trying to end with.\",\n            \"explanation\": \"Circular reasoning lacks logical progression, failing to provide valid support.\"\n        },\n        {\n            \"question\": \"What is a Single Cause Fallacy?\",\n            \"answer\": \"A logical fallacy that assumes there is one simple cause of an outcome when there may be many causes.\",\n            \"explanation\": \"This fallacy oversimplifies complex situations by ignoring multiple contributing factors.\"\n        },\n        {\n            \"question\": \"What does Post hoc, ergo propter hoc mean?\",\n            \"answer\": \"A logical fallacy that assumes one event caused another simply because it occurred first.\",\n            \"explanation\": \"This fallacy overlooks other potential causes or coincidences.\"\n        },\n        {\n            \"question\": \"What are Vague or Undefined Terms?\",\n            \"answer\": \"A logical fallacy where the terms used are unclear or undefined.\",\n            \"explanation\": \"Vague terms can lead to misunderstandings and weaken arguments.\"\n        },\n        {\n            \"question\": \"What is an Unreliable Testimonial?\",\n            \"answer\": \"A fallacy in which a claim is supported by an unreliable or unqualified source.\",\n            \"explanation\": \"Unreliable testimonials lack credibility, undermining the argument's strength.\"\n        },\n        {\n            \"question\": \"What is Equivocation?\",\n            \"answer\": \"A logical fallacy that involves using an ambiguous term in more than one sense.\",\n            \"explanation\": \"Equivocation can mislead by creating confusion around the meaning of terms.\"\n        },\n        {\n            \"question\": \"What is Transfer?\",\n            \"answer\": \"A propaganda technique in which positive or negative feelings from one thing are associated with another.\",\n            \"explanation\": \"Transfer manipulates emotions to influence perceptions of unrelated subjects.\"\n        },\n        {\n            \"question\": \"What is Bandwagon?\",\n            \"answer\": \"A fallacy based on the assumption that the opinion of the majority is always valid.\",\n            \"explanation\": \"Bandwagon appeals to popularity rather than the validity of the argument.\"\n        },\n        {\n            \"question\": \"What is Snob Appeal?\",\n            \"answer\": \"A fallacy in which something is argued to be good because it is elite, special, or rare.\",\n            \"explanation\": \"Snob appeal relies on elitism rather than objective merit.\"\n        },\n        {\n            \"question\": \"What are Loaded Words?\",\n            \"answer\": \"Words that are emotionally charged to influence the audience's perception.\",\n            \"explanation\": \"Loaded words can sway opinions by evoking strong emotional responses.\"\n        },\n        {\n            \"question\": \"What is the difference between Literal and Figurative language?\",\n            \"answer\": \"Literal language means exactly what it says; figurative language uses similes, metaphors, etc.\",\n            \"explanation\": \"Understanding the distinction helps in interpreting texts accurately.\"\n        },\n        {\n            \"question\": \"What is a Clich\u00e9?\",\n            \"answer\": \"A phrase or opinion that is overused and lacks original thought.\",\n            \"explanation\": \"Clich\u00e9s can weaken writing by making it feel unoriginal or uninspired.\"\n        },\n        {\n            \"question\": \"What is an Aphorism?\",\n            \"answer\": \"A pithy observation that contains a general truth.\",\n            \"explanation\": \"Aphorisms convey wisdom in a concise and memorable way.\"\n        },\n        {\n            \"question\": \"What is the difference between Subjective and Objective?\",\n            \"answer\": \"Subjective is based on personal opinions; objective is based on verifiable facts.\",\n            \"explanation\": \"Distinguishing between the two is crucial for critical thinking and analysis.\"\n        },\n        {\n            \"question\": \"What is an Allegory?\",\n            \"answer\": \"A story, poem, or picture that reveals a hidden meaning, typically moral or political.\",\n            \"explanation\": \"Allegories convey deeper messages through symbolism and narrative.\"\n        },\n        {\n            \"question\": \"What is an Epigram?\",\n            \"answer\": \"A pithy saying or remark expressing an idea in a clever and amusing way.\",\n            \"explanation\": \"Epigrams often contain wit and insight, making them memorable.\"\n        },\n        {\n            \"question\": \"What is Satire?\",\n            \"answer\": \"The use of humor, irony, or ridicule to expose and criticize people's stupidity or vices.\",\n            \"explanation\": \"Satire serves to provoke thought and encourage social change through critique.\"\n        },\n        {\n            \"question\": \"What is a Parody?\",\n            \"answer\": \"An imitation of a style with deliberate exaggeration for comic effect.\",\n            \"explanation\": \"Parodies entertain by mocking or exaggerating the original style.\"\n        },\n        {\n            \"question\": \"What does Colloquial mean?\",\n            \"answer\": \"Language used in ordinary conversation; informal.\",\n            \"explanation\": \"Colloquial language reflects everyday speech and can make writing relatable.\"\n        },\n        {\n            \"question\": \"What is Exigence?\",\n            \"answer\": \"The reason or situation that prompts someone to write or speak.\",\n            \"explanation\": \"Exigence highlights the urgency or motivation behind a text's creation.\"\n        }\n    ]\n}"}, {"id": "aa7a3f3d-7a88-4721-aed2-9854222b1a40", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\nScaling: \r\nneural networks (NN): takes in a list of numbers, outputs a list of numbers.\r\nkind of like a really complicated math function\r\nNNs scale very well - larger by adding more weights, learns data effectively\r\n\r\nProbability Distributions(PD) : pairs up events with likelihood of them occurring\r\nprobabilities all have to add up to 1\r\nSamping: picking one event according to its likelihood\r\n\r\nGenerative Models (GM): estimate of a probability distribution\r\nGM of a 6-sided die would assign probability to each # on the die\r\nGMs can take in sequential data - assigning probabilities to sequences\r\ninstead of probs for 1, 2, 3\u2026 (1, 1, 1, 1), (1, 1, 1, 2) etc\u2026\r\n\r\nAutoregressive Models: a generative model that takes a sequence of input and produces a PD over the next token in the sequence; example: (1, 2, 3, 4, 5, 6,??)\r\nproblem: longer sequences = tons of possible sequences\r\n\r\nLanguage Models:\r\nreplacing #s with sequences of letters & symbols\r\nexample: modeling distribution of Shakespeare plays, Poetry, or The Internet\r\ncurrently: machines that are really good at predicting the next token\r\n\r\n\r\nLecture 3\r\n\r\nK-Shot Prompting Challenge: how to ensure LM follows standard format?\r\n-use prompting strategy: control text that is fed int LM\r\n-8-shot prompting: give 8  q/a examples to help prompt\r\n\r\nZero-Shot Prompting: giving no previous example, just question\r\n\r\nChain-of-Thought Prompting (CoT): \r\n-decomposes tasks into smaller steps to simplify\r\n-model outputs reasoning chain before answering\r\nCoT Results:\r\n-performance improvements universally\r\n-more explainable outputs\r\n-to use CoT, prompt with \u201cstep by step\u201d or \u201ctake a deep breath\u201d\r\n\r\nSelf-Consistency/maj@k:\r\n-multiple paths to the correct answer\r\n-combine multiple generations from a model into one final \r\n-improves performance, super reliable, even more than CoT\r\n-majority vote for correct answer (whichever answer was achieved most)\r\n\r\nLM Output:\r\n-outputs score for each token\r\n-higher score = higher probabilities = more likely to come next\r\nInference: stage at which output is used\r\nDecoding: process of generating a sequence from LM\r\n-turning tokens back to text\r\nForward Pass: passing sequence to model, getting scores out of it\r\nConditioning: when using model - feeding the model\r\nLogits: un-normalized next-token scores assigned by LM\r\nGreedy Decoding: taking the highest score token as next \r\n\r\nBeam Search:\r\n-compare sequences against sequences, not tokens against tokens\r\nMethod:\r\n-given B candidate sequences\r\n-pass B into LM for next-token scores for each\r\n-pick top B, throw away the rest\r\n-continue until stopping point\r\n-B is beam width\r\n\r\n\r\n\r\n\r\n\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is when a model fits too closely to the training data, failing to generalize well to new, unseen data.\",\n            \"explanation\": \"Overfitting is undesirable because it means the model performs poorly on data it hasn't seen before, despite potentially performing well on the training data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation occurs when two variables appear to be related, but there is no actual relationship.\",\n            \"explanation\": \"An example is a cow always being in a green background; if the AI assumes it's not a cow when in a different background, it demonstrates spurious correlation.\"\n        },\n        {\n            \"question\": \"What are the three sets in the Train/Validation/Test Split?\",\n            \"answer\": \"Training set, validation set, and test set.\",\n            \"explanation\": \"The training set is used to train the model, the validation set is used to select the best model during training, and the test set is used for final evaluation.\"\n        },\n        {\n            \"question\": \"What is the difference between overfitting and underfitting?\",\n            \"answer\": \"Overfitting occurs when a model is too complex and learns noise in the data, while underfitting happens when a model is too simple to capture the underlying pattern.\",\n            \"explanation\": \"Overfitting results in low training loss but high validation loss, whereas underfitting results in poor performance on both training and validation data.\"\n        },\n        {\n            \"question\": \"What is scaling in the context of neural networks?\",\n            \"answer\": \"Scaling refers to how neural networks can effectively handle larger datasets by adding more weights.\",\n            \"explanation\": \"Neural networks function like complex mathematical functions and can learn data effectively as they scale.\"\n        },\n        {\n            \"question\": \"What are probability distributions?\",\n            \"answer\": \"Probability distributions pair events with their likelihood of occurrence.\",\n            \"explanation\": \"All probabilities in a distribution must sum to 1, and sampling involves picking an event based on its likelihood.\"\n        },\n        {\n            \"question\": \"What are generative models?\",\n            \"answer\": \"Generative models estimate a probability distribution for events.\",\n            \"explanation\": \"An example is a model for a 6-sided die, which assigns probabilities to each number. They can also handle sequential data.\"\n        },\n        {\n            \"question\": \"What is an autoregressive model?\",\n            \"answer\": \"An autoregressive model generates a probability distribution for the next token based on a sequence of input.\",\n            \"explanation\": \"These models can create predictions based on prior sequences, but longer sequences lead to a vast number of potential outcomes.\"\n        },\n        {\n            \"question\": \"What is K-Shot prompting?\",\n            \"answer\": \"K-Shot prompting involves providing a specific number of example question/answer pairs to guide a language model.\",\n            \"explanation\": \"For example, 8-shot prompting gives 8 examples to help the model understand the format of the expected output.\"\n        },\n        {\n            \"question\": \"What is Chain-of-Thought Prompting (CoT)?\",\n            \"answer\": \"CoT decomposes tasks into smaller steps and outputs a reasoning chain before answering.\",\n            \"explanation\": \"This method leads to performance improvements and more explainable outputs, often initiated with prompts like 'step by step'.\"\n        },\n        {\n            \"question\": \"What is self-consistency in language models?\",\n            \"answer\": \"Self-consistency involves generating multiple answers and combining them to find the most reliable result.\",\n            \"explanation\": \"This method improves performance by using a majority vote to determine the correct answer.\"\n        },\n        {\n            \"question\": \"What is the purpose of the inference stage in language models?\",\n            \"answer\": \"Inference is the stage where the model's output is utilized.\",\n            \"explanation\": \"It involves decoding the output, which includes converting tokens back into text.\"\n        },\n        {\n            \"question\": \"What is greedy decoding?\",\n            \"answer\": \"Greedy decoding selects the highest scored token as the next output.\",\n            \"explanation\": \"This method is straightforward but may not always yield the best results compared to more complex decoding strategies.\"\n        },\n        {\n            \"question\": \"What is beam search in language models?\",\n            \"answer\": \"Beam search compares sequences against each other rather than individual tokens.\",\n            \"explanation\": \"It maintains a set number of candidate sequences (beam width) and iteratively selects the top candidates based on their scores.\"\n        }\n    ]\n}"}, {"id": "5e75f96f-cdaf-49cc-816e-a3b1d853462d", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data instead of the underlying pattern, leading to poor performance on unseen data.\"\n        },\n        {\n            \"question\": \"What is a spurious correlation?\",\n            \"answer\": \"A spurious correlation is when data appears to be related, but in reality, it is not.\",\n            \"explanation\": \"An example is a cow always being in a green background; if the AI sees a cow in a different background, it may incorrectly assume it is not a cow due to the misleading correlation.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new, unseen data.\",\n            \"explanation\": \"By splitting the data into training, validation, and test sets, we can train the model, tune it, and finally evaluate its performance without bias.\"\n        },\n        {\n            \"question\": \"What is the training set used for?\",\n            \"answer\": \"The training set is used to train the model by learning the relationship between features and the target variable.\",\n            \"explanation\": \"Typically, the training set comprises 60-80% of the data, allowing the model to learn patterns from the majority of available information.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during the training process.\",\n            \"explanation\": \"It checks how well the model is performing on a smaller portion of the data (10-20%) and helps in tuning the model parameters.\"\n        },\n        {\n            \"question\": \"What is the test set used for?\",\n            \"answer\": \"The test set provides the final evaluation of the model's performance.\",\n            \"explanation\": \"It is only used once (10-20% of data) after the model has been trained and validated, ensuring an unbiased assessment of its effectiveness.\"\n        },\n        {\n            \"question\": \"Why should you never train on the test set?\",\n            \"answer\": \"You should never train on the test set to avoid biasing the performance evaluation.\",\n            \"explanation\": \"Training on the test set would give an unrealistic measure of how well the model performs because it would have already seen the data.\"\n        }\n    ]\n}"}, {"id": "58015e62-2ed8-495a-a4f2-81b24b893e48", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\n\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\nScaling: \r\nneural networks (NN): takes in a list of numbers, outputs a list of numbers.\r\nkind of like a really complicated math function\r\nNNs scale very well - larger by adding more weights, learns data effectively\r\n\r\nProbability Distributions(PD) : pairs up events with likelihood of them occurring\r\nprobabilities all have to add up to 1\r\nSamping: picking one event according to its likelihood\r\n\r\nGenerative Models (GM): estimate of a probability distribution\r\nGM of a 6-sided die would assign probability to each # on the die\r\nGMs can take in sequential data - assigning probabilities to sequences\r\ninstead of probs for 1, 2, 3\u2026 (1, 1, 1, 1), (1, 1, 1, 2) etc\u2026\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well to new unseen data.\",\n            \"explanation\": \"Overfitting is undesirable because it means the model has learned the noise in the training data rather than the underlying pattern.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation occurs when data appears to be related, but there is no actual relationship.\",\n            \"explanation\": \"An example is a cow always being in a green background; if the AI assumes it\u2019s not a cow when in a different background, it demonstrates a spurious correlation.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"The training set is used for learning, the validation set for model selection, and the test set for final evaluation.\"\n        },\n        {\n            \"question\": \"What are the typical proportions of data used in training, validation, and test sets?\",\n            \"answer\": \"Typically, 60-80% of data is used for training, 10-20% for validation, and 10-20% for testing.\",\n            \"explanation\": \"These proportions help ensure that there is enough data to train the model while still having sufficient data to validate and test its performance.\"\n        },\n        {\n            \"question\": \"What is the difference between overfitting and underfitting?\",\n            \"answer\": \"Overfitting occurs when a model is trained too well on the training data, while underfitting happens when a model cannot capture the patterns in the data.\",\n            \"explanation\": \"Overfitting results in low training loss but high validation loss, while underfitting leads to poor performance on all data.\"\n        },\n        {\n            \"question\": \"How do neural networks scale?\",\n            \"answer\": \"Neural networks scale by adding more weights and are capable of learning data effectively.\",\n            \"explanation\": \"They take in a list of numbers and output a list of numbers, functioning like a complicated math function.\"\n        },\n        {\n            \"question\": \"What are probability distributions?\",\n            \"answer\": \"Probability distributions pair up events with their likelihood of occurring, with all probabilities summing to 1.\",\n            \"explanation\": \"Sampling involves picking one event according to its likelihood as defined by the probability distribution.\"\n        },\n        {\n            \"question\": \"What are generative models?\",\n            \"answer\": \"Generative models estimate a probability distribution and can assign probabilities to sequences of data.\",\n            \"explanation\": \"For example, a generative model for a 6-sided die would assign probabilities to each number on the die.\"\n        }\n    ]\n}"}, {"id": "5d789008-9fb7-4733-b623-b5cd5871fff5", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\n\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data instead of the underlying pattern, leading to poor performance on new, unseen data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation occurs when data appears to be related, but there is no true relationship.\",\n            \"explanation\": \"An example is when an AI assumes a cow is not a cow simply because it is in a different background, despite the lack of relevance of the background to the cow itself.\"\n        },\n        {\n            \"question\": \"What are the three main data splits in machine learning?\",\n            \"answer\": \"The three main data splits are training set, validation set, and test set.\",\n            \"explanation\": \"The training set is used to train the model, the validation set helps select the best performing model, and the test set provides a final evaluation of the model's performance.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"By splitting the data, we can train the model on one portion, validate its performance on another, and finally test it on a separate set to evaluate its effectiveness.\"\n        },\n        {\n            \"question\": \"What is the difference between overfitting and underfitting?\",\n            \"answer\": \"Overfitting occurs when a model is too complex and performs poorly on new data, while underfitting occurs when a model is too simple and performs poorly on all data.\",\n            \"explanation\": \"Overfitting is indicated by low training loss and high validation loss, while underfitting shows poor performance across the board.\"\n        },\n        {\n            \"question\": \"What should you never do with the test set?\",\n            \"answer\": \"You should never train on the test set.\",\n            \"explanation\": \"The test set is meant for final evaluation only, and training on it would bias the results and invalidate the assessment of the model's performance.\"\n        }\n    ]\n}"}, {"id": "be8fcb6b-8581-482a-92de-17e0d14fb819", "input": "Lecture 1\n\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\n\nSpurious Correlation: when data appears to be related, but isn\u2019t\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\n\nTrain/Validation/Test Split:\npurpose: prevent overfitting, generalizes well to new unseen data\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\ntest set: provides final evaluation, only used once. (10-20% of data)\nnote: never train on the test set, gauge performance on validation set\n\n\n\nOverfitting vs Underfitting:\noverfitting: trained too well, causing it to perform poorly on new data\nunderfitting: cannot capture pattern of data, performs poorly on all data\nhow to tell overfitting: low train loss, high validation loss\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well to new data.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data rather than the underlying pattern, leading to poor performance on unseen data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation is when data appears to be related but is not actually connected.\",\n            \"explanation\": \"An example is when a cow is always shown against a green background, leading an AI to incorrectly assume that a cow is not a cow if it appears in a different background.\"\n        },\n        {\n            \"question\": \"What is the purpose of the Train/Validation/Test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"The training set is used to train the model, the validation set to tune model performance, and the test set for final evaluation.\"\n        },\n        {\n            \"question\": \"What are the typical proportions of data used in Train/Validation/Test splits?\",\n            \"answer\": \"Typically, 60-80% of data is used for training, 10-20% for validation, and 10-20% for testing.\",\n            \"explanation\": \"These proportions help in effectively training the model while also validating and testing its performance.\"\n        },\n        {\n            \"question\": \"What is the difference between overfitting and underfitting?\",\n            \"answer\": \"Overfitting occurs when a model is trained too well, while underfitting occurs when a model fails to capture the underlying patterns of the data.\",\n            \"explanation\": \"Overfitting leads to low training loss but high validation loss, whereas underfitting results in poor performance across all data.\"\n        },\n        {\n            \"question\": \"How can you identify overfitting?\",\n            \"answer\": \"Overfitting can be identified by observing low training loss and high validation loss.\",\n            \"explanation\": \"This indicates that the model performs well on the training data but poorly on unseen validation data.\"\n        }\n    ]\n}"}, {"id": "afa5968d-5c0a-409f-82a1-90f3255a7bbf", "input": "Lecture 1\n\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\n\nSpurious Correlation: when data appears to be related, but isn\u2019t\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\n\nTrain/Validation/Test Split:\npurpose: prevent overfitting, generalizes well to new unseen data\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\ntest set: provides final evaluation, only used once. (10-20% of data)\nnote: never train on the test set, gauge performance on validation set\n\n\n\nOverfitting vs Underfitting:\noverfitting: trained too well, causing it to perform poorly on new data\nunderfitting: cannot capture pattern of data, performs poorly on all data\nhow to tell overfitting: low train loss, high validation loss\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data instead of the underlying pattern, leading to poor performance on new, unseen data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation is when data appears to be related but is not actually connected.\",\n            \"explanation\": \"An example is a cow always being in a green background; if the AI assumes it\u2019s not a cow in a different background, it demonstrates a false relationship.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"The training set is used to train the model, the validation set helps select the best model, and the test set provides a final evaluation.\"\n        },\n        {\n            \"question\": \"What are the typical proportions of data for training, validation, and testing?\",\n            \"answer\": \"Typically, 60-80% of data is used for training, 10-20% for validation, and 10-20% for testing.\",\n            \"explanation\": \"This split helps ensure that the model is trained effectively while also being validated and tested on separate data.\"\n        },\n        {\n            \"question\": \"What is the difference between overfitting and underfitting?\",\n            \"answer\": \"Overfitting occurs when a model is too complex and performs poorly on new data, while underfitting happens when a model is too simple to capture the underlying patterns.\",\n            \"explanation\": \"Overfitting is indicated by low training loss and high validation loss, while underfitting shows poor performance on all data.\"\n        },\n        {\n            \"question\": \"How can one tell if a model is overfitting?\",\n            \"answer\": \"One can tell if a model is overfitting by observing low training loss and high validation loss.\",\n            \"explanation\": \"This indicates that the model performs well on the training data but fails to generalize to the validation data.\"\n        }\n    ]\n}"}, {"id": "3904e1d7-5b90-4765-aa58-c68726ed450b", "input": "Lecture 1\n\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\n\nSpurious Correlation: when data appears to be related, but isn\u2019t\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\n\nTrain/Validation/Test Split:\npurpose: prevent overfitting, generalizes well to new unseen data\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\ntest set: provides final evaluation, only used once. (10-20% of data)\nnote: never train on the test set, gauge performance on validation set\n\n\n\nOverfitting vs Underfitting:\noverfitting: trained too well, causing it to perform poorly on new data\nunderfitting: cannot capture pattern of data, performs poorly on all data\nhow to tell overfitting: low train loss, high validation loss\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data rather than the underlying pattern, leading to poor performance on new, unseen data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation is when data appears to be related but actually isn't.\",\n            \"explanation\": \"An example is when a cow is always in a green background; if the AI assumes it's not a cow when in a different background, it illustrates how spurious correlations can mislead models.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new, unseen data.\",\n            \"explanation\": \"By splitting the data into training, validation, and test sets, we can train the model, select the best model, and evaluate its performance without bias.\"\n        },\n        {\n            \"question\": \"What is the typical percentage of data used for the training set?\",\n            \"answer\": \"Usually 60-80% of the data is used for the training set.\",\n            \"explanation\": \"The training set is the largest portion of the data, allowing the model to learn the relationships between features and the target variable.\"\n        },\n        {\n            \"question\": \"How is the validation set used in the training process?\",\n            \"answer\": \"The validation set is used to select the best performing model and checks how well the model is performing.\",\n            \"explanation\": \"Typically comprising 10-20% of the data, the validation set helps to tune the model without using the test set.\"\n        },\n        {\n            \"question\": \"What happens during overfitting and underfitting?\",\n            \"answer\": \"Overfitting results in a model that performs poorly on new data, while underfitting fails to capture the pattern of the data.\",\n            \"explanation\": \"Overfitting is indicated by low training loss and high validation loss, while underfitting occurs when the model cannot accurately fit the training data.\"\n        },\n        {\n            \"question\": \"What should you never do with the test set?\",\n            \"answer\": \"You should never train on the test set.\",\n            \"explanation\": \"The test set is meant for final evaluation only and should not influence the training process to ensure an unbiased assessment of model performance.\"\n        }\n    ]\n}"}, {"id": "140d6716-2f8b-41a3-b5ee-88ed9b070ca2", "input": "Lecture 1\n\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\n\nSpurious Correlation: when data appears to be related, but isn\u2019t\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\n\nTrain/Validation/Test Split:\npurpose: prevent overfitting, generalizes well to new unseen data\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\ntest set: provides final evaluation, only used once. (10-20% of data)\nnote: never train on the test set, gauge performance on validation set\n\n\n\nOverfitting vs Underfitting:\noverfitting: trained too well, causing it to perform poorly on new data\nunderfitting: cannot capture pattern of data, performs poorly on all data\nhow to tell overfitting: low train loss, high validation loss\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data rather than the underlying pattern, leading to poor performance on new, unseen data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation is when data appears to be related but actually isn't.\",\n            \"explanation\": \"An example is when a cow is always in a green background; if the AI sees a cow in a different background, it may incorrectly assume it is not a cow, demonstrating a false relationship.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new, unseen data.\",\n            \"explanation\": \"The split allows for training the model, validating its performance during training, and testing its final performance on unseen data.\"\n        },\n        {\n            \"question\": \"What is included in the training set?\",\n            \"answer\": \"The training set is used to train the model and typically consists of 60-80% of the data.\",\n            \"explanation\": \"In the training set, the model learns the relationship between input features and the target output variable.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during the training process.\",\n            \"explanation\": \"It checks how well the model is performing and usually consists of a smaller portion of data (10-20%).\"\n        },\n        {\n            \"question\": \"What is the purpose of the test set?\",\n            \"answer\": \"The test set provides a final evaluation of the model's performance.\",\n            \"explanation\": \"It is only used once and should never be used for training the model; it typically comprises 10-20% of the data.\"\n        },\n        {\n            \"question\": \"What distinguishes overfitting from underfitting?\",\n            \"answer\": \"Overfitting occurs when a model is trained too well, while underfitting occurs when a model cannot capture the patterns of the data.\",\n            \"explanation\": \"Overfitting is indicated by low training loss and high validation loss, whereas underfitting results in poor performance on all data.\"\n        }\n    ]\n}"}, {"id": "27d8c8ca-5d52-4cea-a8b1-f86d2003f3cd", "input": "Lecture 1\n\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\n\nSpurious Correlation: when data appears to be related, but isn\u2019t\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\n\nTrain/Validation/Test Split:\npurpose: prevent overfitting, generalizes well to new unseen data\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\ntest set: provides final evaluation, only used once. (10-20% of data)\nnote: never train on the test set, gauge performance on validation set\n\n\n\nOverfitting vs Underfitting:\noverfitting: trained too well, causing it to perform poorly on new data\nunderfitting: cannot capture pattern of data, performs poorly on all data\nhow to tell overfitting: low train loss, high validation loss\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data rather than the underlying pattern, leading to poor performance on new, unseen data.\"\n        },\n        {\n            \"question\": \"What is a spurious correlation?\",\n            \"answer\": \"A spurious correlation is when data appears to be related but actually is not.\",\n            \"explanation\": \"An example is a model that assumes a cow is not a cow when it is in a different background, despite the cow being in a green background in training data.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and to ensure the model generalizes well to new, unseen data.\",\n            \"explanation\": \"By splitting the data into training, validation, and test sets, we can train the model, tune it, and evaluate its performance without bias.\"\n        },\n        {\n            \"question\": \"What is the typical percentage of data used for the training set?\",\n            \"answer\": \"The training set typically uses 60-80% of the data.\",\n            \"explanation\": \"This portion is used to train the model to learn the relationship between input features and the target output.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during the training process.\",\n            \"explanation\": \"It checks how well the model is performing and is usually a smaller portion of the data, typically 10-20%.\"\n        },\n        {\n            \"question\": \"What is the difference between overfitting and underfitting?\",\n            \"answer\": \"Overfitting occurs when a model is too complex and performs poorly on new data, while underfitting happens when a model is too simple and performs poorly on all data.\",\n            \"explanation\": \"Overfitting is indicated by low training loss and high validation loss, whereas underfitting fails to capture patterns in the data.\"\n        },\n        {\n            \"question\": \"What should never be done with the test set?\",\n            \"answer\": \"You should never train on the test set.\",\n            \"explanation\": \"The test set is meant for final evaluation only and should not influence the training process to ensure an unbiased assessment of model performance.\"\n        }\n    ]\n}"}, {"id": "b2e5602e-2d47-4614-ac07-67648ff89c17", "input": "Scaling: \nneural networks (NN): takes in a list of numbers, outputs a list of numbers.\nkind of like a really complicated math function\nNNs scale very well - larger by adding more weights, learns data effectively\n\nProbability Distributions(PD) : pairs up events with likelihood of them occurring\nprobabilities all have to add up to 1\nSamping: picking one event according to its likelihood\n\nGenerative Models (GM): estimate of a probability distribution\nGM of a 6-sided die would assign probability to each # on the die\nGMs can take in sequential data - assigning probabilities to sequences\ninstead of probs for 1, 2, 3\u2026 (1, 1, 1, 1), (1, 1, 1, 2) etc\u2026\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is a neural network (NN)?\", \n            \"answer\": \"A neural network takes in a list of numbers and outputs a list of numbers.\",\n            \"explanation\": \"Neural networks function similarly to complex mathematical functions, processing input data to produce output data.\"\n        },\n        {\n            \"question\": \"How do neural networks scale?\", \n            \"answer\": \"Neural networks scale by adding more weights.\",\n            \"explanation\": \"This allows them to learn data effectively and handle larger datasets.\"\n        },\n        {\n            \"question\": \"What are probability distributions (PD)?\", \n            \"answer\": \"Probability distributions pair up events with the likelihood of them occurring.\",\n            \"explanation\": \"In a probability distribution, all probabilities must sum up to 1, representing the total certainty of all possible outcomes.\"\n        },\n        {\n            \"question\": \"What does sampling mean in the context of probability distributions?\", \n            \"answer\": \"Sampling refers to picking one event according to its likelihood.\",\n            \"explanation\": \"It involves selecting outcomes based on their assigned probabilities.\"\n        },\n        {\n            \"question\": \"What are generative models (GM)?\", \n            \"answer\": \"Generative models estimate a probability distribution.\",\n            \"explanation\": \"For example, a GM for a 6-sided die assigns probabilities to each number on the die.\"\n        },\n        {\n            \"question\": \"Can generative models handle sequential data?\", \n            \"answer\": \"Yes, generative models can take in sequential data and assign probabilities to sequences.\",\n            \"explanation\": \"Instead of just assigning probabilities to individual numbers, GMs can consider sequences like (1, 1, 1, 1) or (1, 1, 1, 2).\"\n        }\n    ]\n}"}, {"id": "8c4199dd-0669-485f-8155-f8f11a47c11c", "input": "Scaling: \nneural networks (NN): takes in a list of numbers, outputs a list of numbers.\nkind of like a really complicated math function\nNNs scale very well - larger by adding more weights, learns data effectively\n\nProbability Distributions(PD) : pairs up events with likelihood of them occurring\nprobabilities all have to add up to 1\nSamping: picking one event according to its likelihood\n\nGenerative Models (GM): estimate of a probability distribution\nGM of a 6-sided die would assign probability to each # on the die\nGMs can take in sequential data - assigning probabilities to sequences\ninstead of probs for 1, 2, 3\u2026 (1, 1, 1, 1), (1, 1, 1, 2) etc\u2026\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is the primary function of neural networks?\",\n            \"answer\": \"To take in a list of numbers and output a list of numbers.\",\n            \"explanation\": \"Neural networks operate similarly to complex mathematical functions, processing input data and generating output.\"\n        },\n        {\n            \"question\": \"How do neural networks scale?\",\n            \"answer\": \"By adding more weights.\",\n            \"explanation\": \"Neural networks can effectively learn from data and improve their performance by increasing the number of weights.\"\n        },\n        {\n            \"question\": \"What do probability distributions pair up?\",\n            \"answer\": \"Events with the likelihood of them occurring.\",\n            \"explanation\": \"Probability distributions represent the probabilities of different outcomes, which must sum to 1.\"\n        },\n        {\n            \"question\": \"What is sampling in the context of probability distributions?\",\n            \"answer\": \"Picking one event according to its likelihood.\",\n            \"explanation\": \"Sampling involves selecting an event based on its associated probability, reflecting how likely it is to occur.\"\n        },\n        {\n            \"question\": \"What are generative models used for?\",\n            \"answer\": \"To estimate a probability distribution.\",\n            \"explanation\": \"Generative models provide a way to assign probabilities to outcomes, such as the numbers on a die.\"\n        },\n        {\n            \"question\": \"Can generative models handle sequential data?\",\n            \"answer\": \"Yes, they can assign probabilities to sequences.\",\n            \"explanation\": \"Generative models can analyze patterns in sequential data and provide probabilities for various sequences of events.\"\n        }\n    ]\n}"}, {"id": "7792637b-e645-42ba-9306-bdafc067f5e4", "input": "Train/Validation/Test Split:\npurpose: prevent overfitting, generalizes well to new unseen data\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\ntest set: provides final evaluation, only used once. (10-20% of data)\nnote: never train on the test set, gauge performance on validation set\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is the purpose of splitting data into training, validation, and test sets?\",\n            \"answer\": \"To prevent overfitting and to ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"Splitting the data helps to create distinct datasets for training the model, validating its performance during training, and testing its final performance, thus avoiding overfitting.\"\n        },\n        {\n            \"question\": \"What is the training set used for?\",\n            \"answer\": \"The training set is used to train the model.\",\n            \"explanation\": \"It allows the model to learn the relationship between input features and the target output variable, typically comprising 60-80% of the total data.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during training.\",\n            \"explanation\": \"It checks how well the model is performing, typically consisting of a smaller portion of the data (10-20%).\"\n        },\n        {\n            \"question\": \"What is the purpose of the test set?\",\n            \"answer\": \"The test set provides a final evaluation of the model.\",\n            \"explanation\": \"It is only used once after the model has been trained and validated, also typically making up 10-20% of the data.\"\n        },\n        {\n            \"question\": \"What should you never do with the test set?\",\n            \"answer\": \"Never train on the test set.\",\n            \"explanation\": \"Training on the test set would compromise its purpose as a measure of the model's performance; instead, performance should be gauged using the validation set.\"\n        }\n    ]\n}"}, {"id": "45b53165-483e-4f08-aa6f-e3ffd1225423", "input": "Train/Validation/Test Split:\npurpose: prevent overfitting, generalizes well to new unseen data\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\ntest set: provides final evaluation, only used once. (10-20% of data)\nnote: never train on the test set, gauge performance on validation set\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is the purpose of splitting data into training, validation, and test sets?\",\n            \"answer\": \"To prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"By splitting the data, we can train the model effectively while also evaluating its performance on different subsets, which helps in understanding how well it will perform on unseen data.\"\n        },\n        {\n            \"question\": \"What is the training set used for?\",\n            \"answer\": \"The training set is used to train the model.\",\n            \"explanation\": \"The model learns the relationship between features (input variables) and the target (output variable) using the training set, which typically comprises 60-80% of the total data.\"\n        },\n        {\n            \"question\": \"What role does the validation set play in the model training process?\",\n            \"answer\": \"The validation set is used to select the best performing model.\",\n            \"explanation\": \"It checks how well the model is performing during training and typically consists of a smaller portion of data, about 10-20%.\"\n        },\n        {\n            \"question\": \"What is the purpose of the test set?\",\n            \"answer\": \"The test set provides a final evaluation of the model.\",\n            \"explanation\": \"It is used only once after the model has been trained and validated, and it also typically comprises 10-20% of the data.\"\n        },\n        {\n            \"question\": \"What is a crucial note regarding the test set?\",\n            \"answer\": \"Never train on the test set.\",\n            \"explanation\": \"Training on the test set can lead to biased performance metrics, as the model would have already seen the data it is being evaluated on.\"\n        }\n    ]\n}"}]