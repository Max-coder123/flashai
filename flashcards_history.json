[{"id": "de92d447-3281-47c7-8807-b35bc8a9e6a0", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the training data too well, capturing noise and outliers rather than the underlying pattern, which leads to poor performance on new, unseen data.\"\n        },\n        {\n            \"question\": \"What is a spurious correlation?\",\n            \"answer\": \"A spurious correlation occurs when data appears to be related, but there is no actual relationship.\",\n            \"explanation\": \"An example is if a cow is always in a green background; if the AI assumes it's not a cow in a different background, it demonstrates a spurious correlation.\"\n        },\n        {\n            \"question\": \"What is the purpose of the Train/Validation/Test Split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new, unseen data.\",\n            \"explanation\": \"The training set is used to train the model, the validation set helps select the best-performing model, and the test set provides a final evaluation.\"\n        },\n        {\n            \"question\": \"What are the typical data splits for training, validation, and testing?\",\n            \"answer\": \"Typically, 60-80% of data is used for training, 10-20% for validation, and 10-20% for testing.\",\n            \"explanation\": \"This distribution allows the model to learn effectively while also being validated and tested on separate data to assess its performance.\"\n        },\n        {\n            \"question\": \"What is the difference between overfitting and underfitting?\",\n            \"answer\": \"Overfitting occurs when a model is too complex and learns noise, while underfitting occurs when a model is too simple to capture the underlying pattern.\",\n            \"explanation\": \"Overfitting results in low training loss but high validation loss, while underfitting shows poor performance across all data due to insufficient learning.\"\n        },\n        {\n            \"question\": \"How can you identify overfitting in a model?\",\n            \"answer\": \"Overfitting can be identified by observing low training loss and high validation loss.\",\n            \"explanation\": \"This indicates that the model has learned the training data well but struggles to generalize to new, unseen data.\"\n        }\n    ]\n}"}, {"id": "3e44cfd0-a39b-4249-b8f7-eff6d786065c", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well to new unseen data.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise and details in the training data to the extent that it negatively impacts the model's performance on new data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation is when data appears to be related, but in reality, it is not.\",\n            \"explanation\": \"An example is when a cow is always observed in a green background, leading an AI to incorrectly assume that the cow is not a cow when presented with a different background.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"By splitting the data into training, validation, and test sets, we can train the model, tune its parameters, and evaluate its performance without bias.\"\n        },\n        {\n            \"question\": \"What is the typical percentage of data used for the training set?\",\n            \"answer\": \"Typically, 60-80% of the data is used for the training set.\",\n            \"explanation\": \"The training set is the largest portion of the data, allowing the model to learn the relationship between features and the target variable.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during the training process.\",\n            \"explanation\": \"It checks how well the model is performing and is usually a smaller portion of the data (10-20%).\"\n        },\n        {\n            \"question\": \"What is the test set used for?\",\n            \"answer\": \"The test set is used for final evaluation of the model.\",\n            \"explanation\": \"It is only used once and typically comprises 10-20% of the data, ensuring that the model's performance is gauged on unseen data.\"\n        },\n        {\n            \"question\": \"How can you distinguish between overfitting and underfitting?\",\n            \"answer\": \"Overfitting is indicated by low training loss and high validation loss, while underfitting cannot capture the pattern of data and performs poorly on all data.\",\n            \"explanation\": \"Overfitting occurs when the model performs well on training data but poorly on validation data, whereas underfitting means the model fails to learn from the training data effectively.\"\n        }\n    ]\n}"}, {"id": "50e9d27c-4f7e-46ca-8ed3-74e948c90108", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well to new, unseen data.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data instead of the underlying pattern, leading to poor performance on new data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation is when data appears to be related but actually isn't.\",\n            \"explanation\": \"An example is a cow always appearing in a green background; if the AI sees a cow in a different background, it may incorrectly assume it is not a cow due to the false correlation.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"The training set is used to train the model, the validation set helps select the best model, and the test set provides a final evaluation.\"\n        },\n        {\n            \"question\": \"What are the typical proportions of data used for training, validation, and testing?\",\n            \"answer\": \"Typically, 60-80% of data is used for training, 10-20% for validation, and 10-20% for testing.\",\n            \"explanation\": \"These proportions ensure that the model has enough data to learn from while also having a sufficient amount of data to validate and test its performance.\"\n        },\n        {\n            \"question\": \"What is the difference between overfitting and underfitting?\",\n            \"answer\": \"Overfitting occurs when a model is trained too well on the training data, while underfitting happens when a model cannot capture the patterns in the data.\",\n            \"explanation\": \"Overfitting leads to low training loss but high validation loss, whereas underfitting results in poor performance across all data.\"\n        },\n        {\n            \"question\": \"How can you tell if a model is overfitting?\",\n            \"answer\": \"You can tell if a model is overfitting by observing low training loss and high validation loss.\",\n            \"explanation\": \"This indicates that the model performs well on the training data but poorly on unseen validation data, suggesting it has memorized the training data rather than learned to generalize.\"\n        }\n    ]\n}"}, {"id": "3e5d1d21-677e-4d2e-9ca2-40b860370c53", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\nScaling: \r\nneural networks (NN): takes in a list of numbers, outputs a list of numbers.\r\nkind of like a really complicated math function\r\nNNs scale very well - larger by adding more weights, learns data effectively\r\n\r\nProbability Distributions(PD) : pairs up events with likelihood of them occurring\r\nprobabilities all have to add up to 1\r\nSamping: picking one event according to its likelihood\r\n\r\nGenerative Models (GM): estimate of a probability distribution\r\nGM of a 6-sided die would assign probability to each # on the die\r\nGMs can take in sequential data - assigning probabilities to sequences\r\ninstead of probs for 1, 2, 3\u2026 (1, 1, 1, 1), (1, 1, 1, 2) etc\u2026\r\n\r\nAutoregressive Models: a generative model that takes a sequence of input and produces a PD over the next token in the sequence; example: (1, 2, 3, 4, 5, 6,??)\r\nproblem: longer sequences = tons of possible sequences\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is when a model fits too closely to the training data and does not generalize well to new, unseen data.\",\n            \"explanation\": \"Overfitting is undesirable because it means the model performs poorly on data it hasn't seen before, indicating it has learned noise rather than the underlying pattern.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation occurs when two variables appear to be related but are not actually connected.\",\n            \"explanation\": \"An example is a cow always being in a green background; if the background changes, an AI might incorrectly assume it is not a cow, demonstrating that the correlation is not valid.\"\n        },\n        {\n            \"question\": \"What is the purpose of train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new, unseen data.\",\n            \"explanation\": \"The training set is used to train the model, the validation set helps select the best model, and the test set provides a final evaluation of model performance.\"\n        },\n        {\n            \"question\": \"What is the difference between overfitting and underfitting?\",\n            \"answer\": \"Overfitting occurs when a model is too complex and performs poorly on new data, while underfitting happens when a model is too simple and fails to capture the underlying patterns in the data.\",\n            \"explanation\": \"You can identify overfitting by observing low training loss but high validation loss, indicating the model is memorizing the training data.\"\n        },\n        {\n            \"question\": \"How do neural networks scale?\",\n            \"answer\": \"Neural networks scale by adding more weights, which allows them to learn data effectively.\",\n            \"explanation\": \"They function like complex mathematical functions that take in numbers and output numbers, adapting to larger datasets by increasing their capacity.\"\n        },\n        {\n            \"question\": \"What are probability distributions?\",\n            \"answer\": \"Probability distributions pair events with their likelihood of occurring, with all probabilities summing to 1.\",\n            \"explanation\": \"Sampling is the process of selecting one event based on its likelihood, illustrating how probability distributions work.\"\n        },\n        {\n            \"question\": \"What are generative models?\",\n            \"answer\": \"Generative models estimate a probability distribution and can assign probabilities to sequences of data.\",\n            \"explanation\": \"For example, a generative model for a 6-sided die would assign a probability to each number, allowing for the modeling of sequential data.\"\n        },\n        {\n            \"question\": \"What are autoregressive models?\",\n            \"answer\": \"Autoregressive models are a type of generative model that take a sequence of inputs and produce a probability distribution over the next token in the sequence.\",\n            \"explanation\": \"An example is predicting the next number in a sequence like (1, 2, 3, 4, 5, 6, ??), but longer sequences create a vast number of possible outcomes.\"\n        }\n    ]\n}"}, {"id": "1b5d3c76-7b35-486c-995c-22f1889901c2", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\nScaling: \r\nneural networks (NN): takes in a list of numbers, outputs a list of numbers.\r\nkind of like a really complicated math function\r\nNNs scale very well - larger by adding more weights, learns data effectively\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting is undesirable because it means the model performs well on training data but poorly on unseen data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation occurs when data appears to be related, but there is no actual relationship.\",\n            \"explanation\": \"An example is a cow always being in a green background; if the background changes, the AI may incorrectly assume it\u2019s not a cow.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"The training set is used to train the model, the validation set to select the best model, and the test set for final evaluation.\"\n        },\n        {\n            \"question\": \"What are the typical proportions of data used for training, validation, and testing?\",\n            \"answer\": \"Typically, 60-80% of data is used for training, 10-20% for validation, and 10-20% for testing.\",\n            \"explanation\": \"This distribution helps ensure that the model is trained effectively while also being evaluated properly.\"\n        },\n        {\n            \"question\": \"How can you tell if a model is overfitting?\",\n            \"answer\": \"A model is overfitting if it has low training loss but high validation loss.\",\n            \"explanation\": \"This indicates that the model performs well on the training data but fails to generalize to validation data.\"\n        },\n        {\n            \"question\": \"What is the difference between overfitting and underfitting?\",\n            \"answer\": \"Overfitting means the model is too complex and performs poorly on new data, while underfitting means the model is too simple and performs poorly on all data.\",\n            \"explanation\": \"Overfitting captures noise in the training data, while underfitting fails to capture the underlying patterns.\"\n        },\n        {\n            \"question\": \"What is the function of neural networks (NN)?\",\n            \"answer\": \"Neural networks take in a list of numbers and output a list of numbers, functioning like a complex mathematical function.\",\n            \"explanation\": \"They scale well by adding more weights, allowing them to learn data effectively.\"\n        }\n    ]\n}"}, {"id": "fa0b2a43-246f-4662-8621-8bad4103b32e", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\nScaling: \r\nneural networks (NN): takes in a list of numbers, outputs a list of numbers.\r\nkind of like a really complicated math function\r\nNNs scale very well - larger by adding more weights, learns data effectively\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well to new unseen data.\",\n            \"explanation\": \"Overfitting is undesirable because it means the model has learned the noise in the training data rather than the underlying pattern.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation occurs when data appears to be related, but there is no actual relationship.\",\n            \"explanation\": \"An example is when a cow is always in a green background; the AI may incorrectly assume that the color is related to the presence of a cow.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"The training set is for training the model, the validation set is for selecting the best model, and the test set is for final evaluation.\"\n        },\n        {\n            \"question\": \"What are the typical proportions of data used in the train/validation/test split?\",\n            \"answer\": \"Typically, 60-80% for training, 10-20% for validation, and 10-20% for testing.\",\n            \"explanation\": \"These proportions help balance the need for training with the need for accurate validation and testing.\"\n        },\n        {\n            \"question\": \"What is the difference between overfitting and underfitting?\",\n            \"answer\": \"Overfitting occurs when a model is trained too well on the training data, while underfitting happens when a model cannot capture the pattern of the data.\",\n            \"explanation\": \"Overfitting results in low training loss but high validation loss, whereas underfitting results in poor performance across all data.\"\n        },\n        {\n            \"question\": \"How do neural networks scale?\",\n            \"answer\": \"Neural networks scale well by adding more weights, allowing them to learn data effectively.\",\n            \"explanation\": \"This scaling capability enables neural networks to handle larger datasets and more complex patterns.\"\n        }\n    ]\n}"}, {"id": "39ff03a2-6d60-4cf3-93f7-1e52e59a9aeb", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\nScaling: \r\nneural networks (NN): takes in a list of numbers, outputs a list of numbers.\r\nkind of like a really complicated math function\r\nNNs scale very well - larger by adding more weights, learns data effectively\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in poor generalization to new, unseen data.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data instead of the underlying pattern, making it perform poorly on new data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation is when data appears to be related, but actually is not.\",\n            \"explanation\": \"An example is when a cow is always in a green background; if the AI sees it in a different background, it may incorrectly assume it's not a cow, illustrating a false relationship.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new, unseen data.\",\n            \"explanation\": \"The training set is used to train the model, the validation set is used to select the best model, and the test set is for final evaluation.\"\n        },\n        {\n            \"question\": \"What are the typical proportions for training, validation, and test sets?\",\n            \"answer\": \"Training set: 60-80%, Validation set: 10-20%, Test set: 10-20%.\",\n            \"explanation\": \"These proportions help ensure that enough data is available for training while still allowing for validation and testing.\"\n        },\n        {\n            \"question\": \"What is the difference between overfitting and underfitting?\",\n            \"answer\": \"Overfitting occurs when a model is trained too well, leading to poor performance on new data, while underfitting occurs when the model cannot capture the data pattern.\",\n            \"explanation\": \"You can tell overfitting by observing low training loss but high validation loss, indicating that the model memorizes the training data instead of learning general patterns.\"\n        },\n        {\n            \"question\": \"How do neural networks (NNs) function?\",\n            \"answer\": \"Neural networks take in a list of numbers as input and output a list of numbers.\",\n            \"explanation\": \"They function similarly to complex mathematical functions and can scale effectively by adding more weights to learn data.\"\n        }\n    ]\n}"}, {"id": "9de5bc9c-6409-4bb5-879d-1021e571ef8d", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\nScaling: \r\nneural networks (NN): takes in a list of numbers, outputs a list of numbers.\r\nkind of like a really complicated math function\r\nNNs scale very well - larger by adding more weights, learns data effectively\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting is undesirable because it means that the model performs well on the training data but poorly on unseen data, indicating that it has learned noise rather than the underlying pattern.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation occurs when data appears to be related, but there is no actual relationship.\",\n            \"explanation\": \"An example is a cow always being in a green background; if the AI assumes it's not a cow when in a different background, it demonstrates a spurious correlation.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new, unseen data.\",\n            \"explanation\": \"The training set is used to train the model, the validation set to select the best model during training, and the test set for final evaluation.\"\n        },\n        {\n            \"question\": \"What is the difference between overfitting and underfitting?\",\n            \"answer\": \"Overfitting occurs when a model is trained too well on the training data, while underfitting happens when a model cannot capture the underlying patterns of the data.\",\n            \"explanation\": \"Overfitting leads to low training loss but high validation loss, whereas underfitting results in poor performance on both training and validation data.\"\n        },\n        {\n            \"question\": \"How do neural networks scale?\",\n            \"answer\": \"Neural networks scale well by adding more weights and can learn data effectively.\",\n            \"explanation\": \"This scaling allows neural networks to handle larger datasets and more complex relationships, functioning similarly to complicated mathematical functions.\"\n        }\n    ]\n}"}]