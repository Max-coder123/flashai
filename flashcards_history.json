[{"id": "de92d447-3281-47c7-8807-b35bc8a9e6a0", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well.\",\n            \"explanation\": \"Overfitting occurs when a model learns the training data too well, capturing noise and outliers rather than the underlying pattern, which leads to poor performance on new, unseen data.\"\n        },\n        {\n            \"question\": \"What is a spurious correlation?\",\n            \"answer\": \"A spurious correlation occurs when data appears to be related, but there is no actual relationship.\",\n            \"explanation\": \"An example is if a cow is always in a green background; if the AI assumes it's not a cow in a different background, it demonstrates a spurious correlation.\"\n        },\n        {\n            \"question\": \"What is the purpose of the Train/Validation/Test Split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new, unseen data.\",\n            \"explanation\": \"The training set is used to train the model, the validation set helps select the best-performing model, and the test set provides a final evaluation.\"\n        },\n        {\n            \"question\": \"What are the typical data splits for training, validation, and testing?\",\n            \"answer\": \"Typically, 60-80% of data is used for training, 10-20% for validation, and 10-20% for testing.\",\n            \"explanation\": \"This distribution allows the model to learn effectively while also being validated and tested on separate data to assess its performance.\"\n        },\n        {\n            \"question\": \"What is the difference between overfitting and underfitting?\",\n            \"answer\": \"Overfitting occurs when a model is too complex and learns noise, while underfitting occurs when a model is too simple to capture the underlying pattern.\",\n            \"explanation\": \"Overfitting results in low training loss but high validation loss, while underfitting shows poor performance across all data due to insufficient learning.\"\n        },\n        {\n            \"question\": \"How can you identify overfitting in a model?\",\n            \"answer\": \"Overfitting can be identified by observing low training loss and high validation loss.\",\n            \"explanation\": \"This indicates that the model has learned the training data well but struggles to generalize to new, unseen data.\"\n        }\n    ]\n}"}, {"id": "3e44cfd0-a39b-4249-b8f7-eff6d786065c", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well to new unseen data.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise and details in the training data to the extent that it negatively impacts the model's performance on new data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation is when data appears to be related, but in reality, it is not.\",\n            \"explanation\": \"An example is when a cow is always observed in a green background, leading an AI to incorrectly assume that the cow is not a cow when presented with a different background.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"By splitting the data into training, validation, and test sets, we can train the model, tune its parameters, and evaluate its performance without bias.\"\n        },\n        {\n            \"question\": \"What is the typical percentage of data used for the training set?\",\n            \"answer\": \"Typically, 60-80% of the data is used for the training set.\",\n            \"explanation\": \"The training set is the largest portion of the data, allowing the model to learn the relationship between features and the target variable.\"\n        },\n        {\n            \"question\": \"What is the role of the validation set?\",\n            \"answer\": \"The validation set is used to select the best performing model during the training process.\",\n            \"explanation\": \"It checks how well the model is performing and is usually a smaller portion of the data (10-20%).\"\n        },\n        {\n            \"question\": \"What is the test set used for?\",\n            \"answer\": \"The test set is used for final evaluation of the model.\",\n            \"explanation\": \"It is only used once and typically comprises 10-20% of the data, ensuring that the model's performance is gauged on unseen data.\"\n        },\n        {\n            \"question\": \"How can you distinguish between overfitting and underfitting?\",\n            \"answer\": \"Overfitting is indicated by low training loss and high validation loss, while underfitting cannot capture the pattern of data and performs poorly on all data.\",\n            \"explanation\": \"Overfitting occurs when the model performs well on training data but poorly on validation data, whereas underfitting means the model fails to learn from the training data effectively.\"\n        }\n    ]\n}"}, {"id": "50e9d27c-4f7e-46ca-8ed3-74e948c90108", "input": "Lecture 1\r\n\r\nOverfitting: fitting too closely to the data, and not giving a more general result. It is undesirable in ML\r\n\r\nSpurious Correlation: when data appears to be related, but isn\u2019t\r\nie: a cow is always in a green background, but when it\u2019s in a different background, AI assumes it\u2019s not a cow.\r\n\r\nTrain/Validation/Test Split:\r\npurpose: prevent overfitting, generalizes well to new unseen data\r\ntraining set: used to train the model; model learns relationship between features (input variable) and target (output variable). usually 60-80% of data.\r\nvalidation set: used to select the best performing model in the training process. Checks how well model is performing, smaller portion of data (10-20% of data)\r\ntest set: provides final evaluation, only used once. (10-20% of data)\r\nnote: never train on the test set, gauge performance on validation set\r\n\r\nOverfitting vs Underfitting:\r\noverfitting: trained too well, causing it to perform poorly on new data\r\nunderfitting: cannot capture pattern of data, performs poorly on all data\r\nhow to tell overfitting: low train loss, high validation loss\r\n\r\n", "flashcards": "{\n    \"data\": [\n        {\n            \"question\": \"What is overfitting in machine learning?\",\n            \"answer\": \"Overfitting is fitting too closely to the data, resulting in a model that does not generalize well to new, unseen data.\",\n            \"explanation\": \"Overfitting occurs when a model learns the noise in the training data instead of the underlying pattern, leading to poor performance on new data.\"\n        },\n        {\n            \"question\": \"What is spurious correlation?\",\n            \"answer\": \"Spurious correlation is when data appears to be related but actually isn't.\",\n            \"explanation\": \"An example is a cow always appearing in a green background; if the AI sees a cow in a different background, it may incorrectly assume it is not a cow due to the false correlation.\"\n        },\n        {\n            \"question\": \"What is the purpose of the train/validation/test split?\",\n            \"answer\": \"The purpose is to prevent overfitting and ensure the model generalizes well to new unseen data.\",\n            \"explanation\": \"The training set is used to train the model, the validation set helps select the best model, and the test set provides a final evaluation.\"\n        },\n        {\n            \"question\": \"What are the typical proportions of data used for training, validation, and testing?\",\n            \"answer\": \"Typically, 60-80% of data is used for training, 10-20% for validation, and 10-20% for testing.\",\n            \"explanation\": \"These proportions ensure that the model has enough data to learn from while also having a sufficient amount of data to validate and test its performance.\"\n        },\n        {\n            \"question\": \"What is the difference between overfitting and underfitting?\",\n            \"answer\": \"Overfitting occurs when a model is trained too well on the training data, while underfitting happens when a model cannot capture the patterns in the data.\",\n            \"explanation\": \"Overfitting leads to low training loss but high validation loss, whereas underfitting results in poor performance across all data.\"\n        },\n        {\n            \"question\": \"How can you tell if a model is overfitting?\",\n            \"answer\": \"You can tell if a model is overfitting by observing low training loss and high validation loss.\",\n            \"explanation\": \"This indicates that the model performs well on the training data but poorly on unseen validation data, suggesting it has memorized the training data rather than learned to generalize.\"\n        }\n    ]\n}"}]